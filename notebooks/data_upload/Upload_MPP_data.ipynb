{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1a114d-c1f8-4b35-b2e1-16d3ccb9de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4840fec7-727b-4454-bed3-25d603203b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62d1d0-c994-48e0-ac76-dd797484f5bc",
   "metadata": {},
   "source": [
    "# Upload all mpp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a027254a-35a5-4b2c-b066-b64905e68c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def process_mpp_files(root_dir, engine):\n",
    "    \"\"\"\n",
    "    Crawls directories starting with 'data', finds files matching the pattern,\n",
    "    reads them into pandas DataFrames, and uploads them to the DB.\n",
    "\n",
    "    Args:\n",
    "        root_dir: The root directory to start the search from.\n",
    "        engine:   SQLAlchemy engine for database connection.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile the regex pattern for efficiency\n",
    "    pattern = re.compile(r\"output_board(\\d+)_channel(\\d+)\")\n",
    "\n",
    "    # First, collect all matching filepaths\n",
    "    matching_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        if any(dir.startswith(\"data\") for dir in os.path.normpath(dirpath).split(os.sep)):\n",
    "            for filename in filenames:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                if pattern.search(filename):\n",
    "                    matching_files.append(filepath)\n",
    "\n",
    "    # Now, process the collected filepaths\n",
    "    with tqdm(total=len(matching_files), desc=\"Processing MPP Files\") as pbar:\n",
    "        for filepath in matching_files:\n",
    "            try:\n",
    "                # Extract filename for pattern matching (use os.path.basename)\n",
    "                filename = os.path.basename(filepath)\n",
    "                match = pattern.search(filename)\n",
    "\n",
    "                # Extract board and channel numbers\n",
    "                board = int(match.group(1))\n",
    "                channel = int(match.group(2))\n",
    "                # Read the file into a pandas DataFrame\n",
    "                df = pd.read_csv(filepath, sep='\\t',\n",
    "                                 names=['timestamp', 'power', 'current', 'voltage'])  # Adjust read function if needed\n",
    "                df.timestamp = pd.to_datetime(df.timestamp, utc=True)  # Ensure UTC timezone\n",
    "\n",
    "                # Add board and channel information to the DataFrame\n",
    "                df['tracking_channel_board'] = board\n",
    "                df['tracking_channel_channel'] = channel\n",
    "\n",
    "                # --- Check for Existing Data ---\n",
    "                timestamps_to_check = df['timestamp'].tolist()\n",
    "                board_id = board\n",
    "                channel_id = channel\n",
    "\n",
    "                # --- Check for Existing Data (Last Timestamp Only) ---\n",
    "                last_timestamp = df['timestamp'].iloc[-1]  # Get the last timestamp\n",
    "\n",
    "                # Build a query to check for existing data\n",
    "                query = text(\"\"\"\n",
    "                    SELECT 1\n",
    "                    FROM mpp_measurement\n",
    "                    WHERE timestamp = :last_timestamp\n",
    "                      AND tracking_channel_board = :board_id\n",
    "                      AND tracking_channel_channel = :channel_id\n",
    "                \"\"\")\n",
    "\n",
    "                # Execute the query\n",
    "                with engine.connect() as conn:\n",
    "                    result = conn.execute(query, {\n",
    "                        \"last_timestamp\": last_timestamp,\n",
    "                        \"board_id\": board,\n",
    "                        \"channel_id\": channel\n",
    "                    })\n",
    "                    exists = result.fetchone() is not None  # Check if any row was returned\n",
    "\n",
    "                if not exists:\n",
    "                    # Upload the entire DataFrame\n",
    "                    df.to_sql('mpp_measurement', engine, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "                del df\n",
    "                pbar.update(1)  # Increment progress bar\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filepath}: {e}\")  # Print errors\n",
    "                pbar.update(1)  # Increment progress bar even on error\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e847a3b-a477-4960-b3a3-ad77ef6e13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://postgres:password@timescaledb:5432/perocube\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df07af7-7e2f-4c1f-b3b5-2c4654a5095c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c471ede92f2d4ee2979052a21d92f7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing MPP Files:   0%|          | 0/1897 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_directory = \".\"\n",
    "all_dataframes = process_mpp_files(root_directory, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903bb13-401b-46f8-aa03-0a5127af9d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
