{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2870f38a",
   "metadata": {},
   "source": [
    "# Temperature & Irradiance Data Upload Notebook\n",
    "\n",
    "This notebook processes and uploads temperature and irradiance sensor data from text files to the TimescaleDB database.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "- Scan directories for temperature and irradiance data files\n",
    "- Register sensor metadata in the database\n",
    "- Upload measurement data to the TimescaleDB database\n",
    "- Avoid duplicate data entries\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Running TimescaleDB instance (configured in docker-compose.yml)\n",
    "- Access to directory containing temperature and irradiance data files\n",
    "- Environment variables configured in .env file (for database connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87661cb7",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import required libraries and install any missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180ffac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (2.0.40)\n",
      "Requirement already satisfied: pandas in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: pathlib in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dotenv in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Requirement already satisfied: uuid in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (1.30)\n",
      "Requirement already satisfied: greenlet>=1 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from sqlalchemy) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from sqlalchemy) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/qkg/Documents/1_PROJECTS/Perocube Data Monitoring System/perocube-data-monitoring-system/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install psycopg2-binary sqlalchemy pandas tqdm pathlib python-dotenv uuid\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d6f2e1-0e2b-4ea5-acc4-b84fe5cf633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "# Database libraries\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f945766",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Load configuration from environment variables or use defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b36fdc",
   "metadata": {},
   "source": [
    "## TimescaleDB and Measurement Tables Note\n",
    "\n",
    "Important note about TimescaleDB tables:\n",
    "\n",
    "1. The measurement tables (`irradiance_measurement`, `temperature_measurement`, etc.) are hypertables in TimescaleDB.\n",
    "2. These tables do **not** have a traditional primary key column named 'id'.\n",
    "3. Instead, they use the `timestamp` column as their primary dimension for partitioning and indexing.\n",
    "4. When checking for existing data, we must use the `timestamp` column rather than looking for an 'id' column.\n",
    "\n",
    "This is a key difference from regular PostgreSQL tables and affects how we check for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2059eabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection: localhost:5432/perocube as postgres\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "# Look for the .env file two directories up from the notebook location\n",
    "dotenv_path = Path(\"../../.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Database configuration from environment variables with fallbacks\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),  # Changed from 'timescaledb' to 'localhost'\n",
    "    'port': int(os.getenv('DB_PORT', 5432)),\n",
    "    'database': os.getenv('DB_NAME', 'perocube'),\n",
    "    'user': os.getenv('DB_USER', 'postgres'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'postgres')\n",
    "}\n",
    "\n",
    "# Print database connection info (excluding password)\n",
    "print(f\"Database connection: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']} as {DB_CONFIG['user']}\")\n",
    "\n",
    "# Data directory configuration\n",
    "ROOT_DIRECTORY = os.getenv('DEFAULT_DATA_DIR', \"../../sample_data/datasets/PeroCube-sample-data\")\n",
    "\n",
    "# File matching patterns\n",
    "IRRADIANCE_FILE_PATTERN = r\"PT-(\\d+)_channel_(\\d+)\"  # Matches PT-104_channel_01.txt\n",
    "TEMPERATURE_FILE_PATTERN = r\"m7004_ID_(\\w+)\"\n",
    "\n",
    "# Batch size for database operations\n",
    "BATCH_SIZE = 5000\n",
    "\n",
    "# Data validation configuration\n",
    "VALIDATION_CONFIG = {\n",
    "    'enabled': False,  # Master switch for validation\n",
    "    'remove_nan': True,  # Always remove NaN values\n",
    "    'validate_ranges': False,  # Optional physical value validation\n",
    "    'ranges': {\n",
    "        'irradiance': {'min': 0, 'max': 1500},  # W/m²\n",
    "        'temperature': {'min': -50, 'max': 100}  # °C\n",
    "    }\n",
    "}\n",
    "\n",
    "def print_validation_config():\n",
    "    \"\"\"Print current validation configuration for user awareness\"\"\"\n",
    "    print(\"\\nData Validation Configuration:\")\n",
    "    print(f\"- Validation enabled: {VALIDATION_CONFIG['enabled']}\")\n",
    "    print(f\"- Remove NaN values: {VALIDATION_CONFIG['remove_nan']}\")\n",
    "    if VALIDATION_CONFIG['enabled'] and VALIDATION_CONFIG['validate_ranges']:\n",
    "        print(\"\\nPhysical value ranges:\")\n",
    "        for measure, limits in VALIDATION_CONFIG['ranges'].items():\n",
    "            print(f\"- {measure}: {limits['min']} to {limits['max']}\")\n",
    "    else:\n",
    "        print(\"\\nPhysical value validation is disabled\")\n",
    "\n",
    "# Table names\n",
    "IRRADIANCE_SENSOR_TABLE = 'irradiance_sensor'\n",
    "IRRADIANCE_MEASUREMENT_TABLE = 'irradiance_measurement'\n",
    "TEMPERATURE_SENSOR_TABLE = 'temperature_sensor'\n",
    "TEMPERATURE_MEASUREMENT_TABLE = 'temperature_measurement'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ea590-f67b-4461-8722-93908204baed",
   "metadata": {},
   "source": [
    "## 3. Utility Functions\n",
    "\n",
    "Helper functions for database connection and data validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d20f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_connection(config=DB_CONFIG):\n",
    "    \"\"\"\n",
    "    Create a SQLAlchemy database engine from configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: Dictionary containing database connection parameters\n",
    "        \n",
    "    Returns:\n",
    "        SQLAlchemy engine instance\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection_string = f\"postgresql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\"\n",
    "        # Store connection string as attribute of engine for external access\n",
    "        engine = create_engine(connection_string)\n",
    "        engine.connection_string = connection_string  # This makes it accessible via engine.connection_string\n",
    "        \n",
    "        # Test the connection\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT 1\"))\n",
    "            logging.info(f\"Database connection successful: {config['host']}:{config['port']}/{config['database']}\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Database connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_irradiance_data(df, config=VALIDATION_CONFIG):\n",
    "    \"\"\"\n",
    "    Validate irradiance data according to the specified configuration.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing irradiance measurements\n",
    "        config: Dictionary containing validation configuration\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned and validated DataFrame, along with validation statistics\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df, {'initial_count': 0, 'final_count': 0, 'removed': {}}\n",
    "    \n",
    "    stats = {\n",
    "        'initial_count': len(df),\n",
    "        'final_count': None,\n",
    "        'removed': {\n",
    "            'nan_values': 0,\n",
    "            'irradiance_range': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Always ensure timestamp is in UTC\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "    \n",
    "    # Remove NaN values if configured\n",
    "    if config['remove_nan']:\n",
    "        nan_count = df.isna().sum().sum()\n",
    "        df = df.dropna()\n",
    "        stats['removed']['nan_values'] = nan_count\n",
    "    \n",
    "    # Apply physical value validation if enabled\n",
    "    if config['enabled'] and config['validate_ranges']:\n",
    "        if 'irradiance' in df.columns and 'irradiance' in config['ranges']:\n",
    "            limits = config['ranges']['irradiance']\n",
    "            invalid_count = len(df[~(df['irradiance'].between(limits['min'], limits['max']))])\n",
    "            df = df[df['irradiance'].between(limits['min'], limits['max'])]\n",
    "            stats['removed']['irradiance_range'] = invalid_count\n",
    "    \n",
    "    stats['final_count'] = len(df)\n",
    "    \n",
    "    # Log validation results\n",
    "    logging.info(\"Validation statistics:\")\n",
    "    logging.info(f\"Initial records: {stats['initial_count']}\")\n",
    "    if config['remove_nan']:\n",
    "        logging.info(f\"Removed NaN values: {stats['removed']['nan_values']}\")\n",
    "    if config['enabled'] and config['validate_ranges']:\n",
    "        if stats['removed']['irradiance_range'] > 0:\n",
    "            logging.info(f\"Removed irradiance out of range: {stats['removed']['irradiance_range']}\")\n",
    "    logging.info(f\"Final records: {stats['final_count']}\")\n",
    "    \n",
    "    return df, stats\n",
    "\n",
    "def validate_temperature_data(df, config=VALIDATION_CONFIG):\n",
    "    \"\"\"\n",
    "    Validate temperature data according to the specified configuration.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing temperature measurements\n",
    "        config: Dictionary containing validation configuration\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned and validated DataFrame, along with validation statistics\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df, {'initial_count': 0, 'final_count': 0, 'removed': {}}\n",
    "    \n",
    "    stats = {\n",
    "        'initial_count': len(df),\n",
    "        'final_count': None,\n",
    "        'removed': {\n",
    "            'nan_values': 0,\n",
    "            'temperature_range': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Always ensure timestamp is in UTC\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "    \n",
    "    # Remove NaN values if configured\n",
    "    if config['remove_nan']:\n",
    "        nan_count = df.isna().sum().sum()\n",
    "        df = df.dropna()\n",
    "        stats['removed']['nan_values'] = nan_count\n",
    "    \n",
    "    # Apply physical value validation if enabled\n",
    "    if config['enabled'] and config['validate_ranges']:\n",
    "        if 'temperature' in df.columns and 'temperature' in config['ranges']:\n",
    "            limits = config['ranges']['temperature']\n",
    "            invalid_count = len(df[~(df['temperature'].between(limits['min'], limits['max']))])\n",
    "            df = df[df['temperature'].between(limits['min'], limits['max'])]\n",
    "            stats['removed']['temperature_range'] = invalid_count\n",
    "    \n",
    "    stats['final_count'] = len(df)\n",
    "    \n",
    "    # Log validation results\n",
    "    logging.info(\"Validation statistics:\")\n",
    "    logging.info(f\"Initial records: {stats['initial_count']}\")\n",
    "    if config['remove_nan']:\n",
    "        logging.info(f\"Removed NaN values: {stats['removed']['nan_values']}\")\n",
    "    if config['enabled'] and config['validate_ranges']:\n",
    "        if stats['removed']['temperature_range'] > 0:\n",
    "            logging.info(f\"Removed temperature out of range: {stats['removed']['temperature_range']}\")\n",
    "    logging.info(f\"Final records: {stats['final_count']}\")\n",
    "    \n",
    "    return df, stats\n",
    "\n",
    "def check_existing_data(engine, table, sensor_id_col, sensor_id, timestamp, id_field='timestamp'):\n",
    "    \"\"\"\n",
    "    Check if data already exists in the database for given parameters.\n",
    "    \n",
    "    Args:\n",
    "        engine: SQLAlchemy engine\n",
    "        table: Table name\n",
    "        sensor_id_col: Column name for sensor ID\n",
    "        sensor_id: Sensor ID value\n",
    "        timestamp: Timestamp to check\n",
    "        id_field: Primary key field name (defaults to timestamp as hypertables use timestamp as primary dimension)\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if data exists\n",
    "    \"\"\"\n",
    "    if not timestamp:\n",
    "        return False\n",
    "        \n",
    "    # Build a query to check for existing data\n",
    "    query = text(f\"\"\"\n",
    "        SELECT {id_field}\n",
    "        FROM {table}\n",
    "        WHERE timestamp = :timestamp\n",
    "          AND {sensor_id_col} = :sensor_id\n",
    "        LIMIT 1\n",
    "    \"\"\")\n",
    "    \n",
    "    # Execute the query\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"sensor_id\": sensor_id\n",
    "        })\n",
    "        row = result.fetchone()\n",
    "        \n",
    "    # If row is not None, data exists\n",
    "    return row is not None\n",
    "\n",
    "def get_sensor_id(engine, sensor_table, name_col, name_val, channel_col=None, channel_val=None):\n",
    "    \"\"\"\n",
    "    Get sensor ID from the database or create if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        engine: SQLAlchemy engine\n",
    "        sensor_table: Sensor table name\n",
    "        name_col: Column name for sensor name\n",
    "        name_val: Sensor name value\n",
    "        channel_col: Column name for channel (optional)\n",
    "        channel_val: Channel value (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Sensor ID\n",
    "    \"\"\"\n",
    "    # Build the query based on whether channel is provided\n",
    "    if channel_col and channel_val is not None:\n",
    "        query = text(f\"\"\"\n",
    "            SELECT {sensor_table}_id FROM {sensor_table} \n",
    "            WHERE {name_col} = :name_val AND {channel_col} = :channel_val\n",
    "        \"\"\")\n",
    "        params = {\"name_val\": name_val, \"channel_val\": channel_val}\n",
    "    else:\n",
    "        query = text(f\"\"\"\n",
    "            SELECT {sensor_table}_id FROM {sensor_table} \n",
    "            WHERE {name_col} = :name_val\n",
    "        \"\"\")\n",
    "        params = {\"name_val\": name_val}\n",
    "    \n",
    "    # Execute the query\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, params)\n",
    "        row = result.fetchone()\n",
    "        \n",
    "    # Return the ID if found\n",
    "    if row:\n",
    "        return row[0]\n",
    "    else:\n",
    "        logging.warning(f\"Sensor not found: {name_val} in {sensor_table}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45911c6b",
   "metadata": {},
   "source": [
    "## 4. Sensor Registration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5554de48-89aa-4058-82de-8d53637f46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_irradiance_sensors(root_dir, engine, pattern=IRRADIANCE_FILE_PATTERN):\n",
    "    \"\"\"\n",
    "    Scan directories for irradiance sensor files and register unique sensors in the database.\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'sensors_found': 0,\n",
    "        'sensors_registered': 0,\n",
    "        'sensors_existing': 0\n",
    "    }\n",
    "    \n",
    "    # Convert to Path object for better path handling\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        logging.error(f\"Root directory does not exist: {root_dir}\")\n",
    "        return stats\n",
    "    \n",
    "    # Compile the regex pattern for efficiency\n",
    "    pattern_compiled = re.compile(pattern)\n",
    "    \n",
    "    # Create a DataFrame to store sensor information\n",
    "    irradiance_sensors = pd.DataFrame(columns=[\n",
    "        'irradiance_sensor_id', 'date_installed', 'location', \n",
    "        'installation_angle', 'sensor_identifier', 'channel'\n",
    "    ])\n",
    "    existing_sensors = set()  # Track unique sensor/channel combinations\n",
    "\n",
    "    # First, get all existing sensors from the database\n",
    "    query = text(f\"\"\"\n",
    "        SELECT sensor_identifier, channel, irradiance_sensor_id\n",
    "        FROM {IRRADIANCE_SENSOR_TABLE}\n",
    "    \"\"\")\n",
    "    sensor_mapping = {}\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        for row in result:\n",
    "            # FIXED: Store the key in the same consistent format\n",
    "            sensor_key = f\"{row.sensor_identifier}_{row.channel}\"\n",
    "            sensor_mapping[sensor_key] = row.irradiance_sensor_id\n",
    "\n",
    "    # Scan directories for sensor files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        path_parts = Path(dirpath).parts\n",
    "        if any(part.startswith(\"data\") for part in path_parts):\n",
    "            for filename in filenames:\n",
    "                match = pattern_compiled.search(filename)\n",
    "                if match:\n",
    "                    sensor_number = match.group(1)  # PT-{number}\n",
    "                    channel = int(match.group(2))      # channel_{number}\n",
    "                    sensor_identifier = f\"PT-{sensor_number}\"\n",
    "                    \n",
    "                    # FIXED: Use a consistent key format\n",
    "                    sensor_key = f\"{sensor_identifier}_{channel}\"  \n",
    "                    \n",
    "                    if sensor_key not in existing_sensors:\n",
    "                        # Check if sensor already exists in database\n",
    "                        if sensor_key in sensor_mapping:\n",
    "                            sensor_id = sensor_mapping[sensor_key]\n",
    "                            stats['sensors_existing'] += 1\n",
    "                        else:\n",
    "                            # Only generate new UUID for new sensors\n",
    "                            sensor_id = str(uuid.uuid4())\n",
    "                            # Create a new sensor entry\n",
    "                            sensor_data = {\n",
    "                                'irradiance_sensor_id': sensor_id,\n",
    "                                'date_installed': None,  # Will be set when actual installation date is known\n",
    "                                'location': None,       # Will be set to represent physical location in PV system\n",
    "                                'installation_angle': 0, # Will be set to actual installation angle\n",
    "                                'sensor_identifier': sensor_identifier,\n",
    "                                'channel': channel\n",
    "                            }\n",
    "                            \n",
    "                            # Add to DataFrame\n",
    "                            irradiance_sensors = pd.concat([irradiance_sensors, pd.DataFrame([sensor_data])], ignore_index=True)\n",
    "                            stats['sensors_found'] += 1\n",
    "                        \n",
    "                        existing_sensors.add(sensor_key)\n",
    "\n",
    "    # Insert only new sensors into the database\n",
    "    for _, sensor in irradiance_sensors.iterrows():\n",
    "        try:\n",
    "            # Convert NaN to None\n",
    "            sensor_dict = {k: (None if pd.isna(v) else v) for k, v in sensor.items()}\n",
    "            \n",
    "            insert_query = text(f\"\"\"\n",
    "                INSERT INTO {IRRADIANCE_SENSOR_TABLE} \n",
    "                (irradiance_sensor_id, date_installed, location, installation_angle, sensor_identifier, channel)\n",
    "                VALUES (:irradiance_sensor_id, :date_installed, :location, :installation_angle, :sensor_identifier, :channel)\n",
    "                ON CONFLICT (sensor_identifier, channel) DO NOTHING\n",
    "            \"\"\")\n",
    "            \n",
    "            with engine.connect() as conn:\n",
    "                result = conn.execute(insert_query, sensor_dict)\n",
    "                conn.commit()\n",
    "                if result.rowcount > 0:\n",
    "                    stats['sensors_registered'] += 1\n",
    "                    logging.info(f\"Registered irradiance sensor: {sensor['sensor_identifier']} channel {sensor['channel']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to register sensor {sensor['sensor_identifier']} channel {sensor['channel']}: {str(e)}\")\n",
    "    \n",
    "    logging.info(f\"Found {stats['sensors_found']} unique irradiance sensors\")\n",
    "    logging.info(f\"Registered {stats['sensors_registered']} new irradiance sensors\")\n",
    "    logging.info(f\"Found {stats['sensors_existing']} existing irradiance sensors\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def register_temperature_sensors(root_dir, engine, pattern=TEMPERATURE_FILE_PATTERN):\n",
    "    \"\"\"\n",
    "    Scan directories for temperature sensor files and register unique sensors in the database.\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'sensors_found': 0,\n",
    "        'sensors_registered': 0,\n",
    "        'sensors_existing': 0\n",
    "    }\n",
    "    \n",
    "    # Convert to Path object for better path handling\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        logging.error(f\"Root directory does not exist: {root_dir}\")\n",
    "        return stats\n",
    "    \n",
    "    # Compile the regex pattern for efficiency\n",
    "    pattern_compiled = re.compile(pattern)\n",
    "    \n",
    "    # Create a DataFrame to store sensor information\n",
    "    temperature_sensors = pd.DataFrame(columns=[\n",
    "        'temperature_sensor_id', 'date_installed', 'location', \n",
    "        'sensor_identifier'\n",
    "    ])\n",
    "    existing_sensors = set()  # Track unique sensors\n",
    "\n",
    "    # First, get all existing sensors from the database\n",
    "    query = text(f\"\"\"\n",
    "        SELECT sensor_identifier, temperature_sensor_id\n",
    "        FROM {TEMPERATURE_SENSOR_TABLE}\n",
    "    \"\"\")\n",
    "    sensor_mapping = {}\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        for row in result:\n",
    "            sensor_mapping[row.sensor_identifier] = row.temperature_sensor_id\n",
    "\n",
    "    # Scan directories for sensor files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        path_parts = Path(dirpath).parts\n",
    "        if any(part.startswith(\"data\") for part in path_parts):\n",
    "            for filename in filenames:\n",
    "                match = pattern_compiled.search(filename)\n",
    "                if match:\n",
    "                    sensor_number = match.group(1)  # TE-{number}\n",
    "                    sensor_identifier = f\"TE-{sensor_number}\"\n",
    "                    \n",
    "                    if sensor_identifier not in existing_sensors:\n",
    "                        # Check if sensor already exists in database\n",
    "                        if sensor_identifier in sensor_mapping:\n",
    "                            sensor_id = sensor_mapping[sensor_identifier]\n",
    "                            stats['sensors_existing'] += 1\n",
    "                        else:\n",
    "                            # Only generate new UUID for new sensors\n",
    "                            sensor_id = str(uuid.uuid4())\n",
    "                            # Create a new sensor entry\n",
    "                            sensor_data = {\n",
    "                                'temperature_sensor_id': sensor_id,\n",
    "                                'date_installed': None,  # Will be set when actual installation date is known\n",
    "                                'location': None,       # Will be set to represent physical location in PV system\n",
    "                                'sensor_identifier': sensor_identifier\n",
    "                            }\n",
    "                            \n",
    "                            # Add to DataFrame\n",
    "                            temperature_sensors = pd.concat([temperature_sensors, pd.DataFrame([sensor_data])], ignore_index=True)\n",
    "                            stats['sensors_found'] += 1\n",
    "                        \n",
    "                        existing_sensors.add(sensor_identifier)\n",
    "\n",
    "    # Insert only new sensors into the database\n",
    "    for _, sensor in temperature_sensors.iterrows():\n",
    "        try:\n",
    "            # Convert NaN to None\n",
    "            sensor_dict = {k: (None if pd.isna(v) else v) for k, v in sensor.items()}\n",
    "            \n",
    "            insert_query = text(f\"\"\"\n",
    "                INSERT INTO {TEMPERATURE_SENSOR_TABLE} \n",
    "                (temperature_sensor_id, date_installed, location, sensor_identifier)\n",
    "                VALUES (:temperature_sensor_id, :date_installed, :location, :sensor_identifier)\n",
    "                ON CONFLICT (sensor_identifier) DO NOTHING\n",
    "            \"\"\")\n",
    "            \n",
    "            with engine.connect() as conn:\n",
    "                result = conn.execute(insert_query, sensor_dict)\n",
    "                conn.commit()\n",
    "                if result.rowcount > 0:\n",
    "                    stats['sensors_registered'] += 1\n",
    "                    logging.info(f\"Registered temperature sensor: {sensor['sensor_identifier']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to register sensor {sensor['sensor_identifier']}: {str(e)}\")\n",
    "    \n",
    "    logging.info(f\"Found {stats['sensors_found']} unique temperature sensors\")\n",
    "    logging.info(f\"Registered {stats['sensors_registered']} new temperature sensors\")\n",
    "    logging.info(f\"Found {stats['sensors_existing']} existing temperature sensors\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658b804",
   "metadata": {},
   "source": [
    "## 5. Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0494d4-6a4f-4874-924e-d6ec1da9be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_irradiance_files(root_dir, engine, pattern=IRRADIANCE_FILE_PATTERN, batch_size=BATCH_SIZE, validate=VALIDATION_CONFIG['enabled']):\n",
    "    \"\"\"\n",
    "    Process irradiance data files and upload to database.\n",
    "    \"\"\"\n",
    "    # Statistics to return\n",
    "    stats = {\n",
    "        'files_processed': 0,\n",
    "        'files_skipped': 0,\n",
    "        'files_error': 0,\n",
    "        'rows_inserted': 0,\n",
    "        'start_time': datetime.now(timezone.utc),\n",
    "        'total_files': 0\n",
    "    }\n",
    "\n",
    "    # Convert to Path object for better path handling\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        logging.error(f\"Root directory does not exist: {root_dir}\")\n",
    "        return stats\n",
    "\n",
    "    # Compile the regex pattern for efficiency\n",
    "    pattern_compiled = re.compile(pattern)\n",
    "\n",
    "    # First, collect all matching filepaths\n",
    "    matching_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        path_parts = Path(dirpath).parts\n",
    "        if any(part.startswith(\"data\") for part in path_parts):\n",
    "            for filename in filenames:\n",
    "                filepath = Path(dirpath) / filename\n",
    "                if pattern_compiled.search(filename):\n",
    "                    matching_files.append(filepath)\n",
    "\n",
    "    stats['total_files'] = len(matching_files)\n",
    "    logging.info(f\"Found {len(matching_files)} irradiance data files to process\")\n",
    "\n",
    "    # Create a mapping of sensor identifiers and channels to database IDs\n",
    "    query = text(f\"\"\"SELECT irradiance_sensor_id, sensor_identifier, channel FROM {IRRADIANCE_SENSOR_TABLE}\"\"\")\n",
    "    sensor_mapping = {}\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        for row in result:\n",
    "            sensor_mapping[f\"{row.sensor_identifier}_{row.channel}\"] = row.irradiance_sensor_id\n",
    "    \n",
    "    if not sensor_mapping:\n",
    "        logging.error(\"No irradiance sensors registered in the database\")\n",
    "        return stats\n",
    "\n",
    "    # Process files with a progress bar\n",
    "    with tqdm(total=len(matching_files), desc=\"Processing Irradiance Files\") as pbar:\n",
    "        for filepath in matching_files:\n",
    "            try:\n",
    "                # Extract sensor info from filename\n",
    "                match = pattern_compiled.search(filepath.name)\n",
    "                if not match:\n",
    "                    logging.warning(f\"Could not parse sensor info from filename: {filepath}\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                sensor_number = match.group(1)  # This gets \"104\" from \"PT-104_channel_01\"\n",
    "                channel = int(match.group(2))      # This gets \"01\" from \"PT-104_channel_01\"\n",
    "                sensor_identifier = f\"PT-{sensor_number}\"\n",
    "                sensor_key = f\"{sensor_identifier}_{channel}\"  # Construct key to match actual filename pattern\n",
    "                \n",
    "                # Look up sensor ID from mapping\n",
    "                sensor_id = sensor_mapping.get(sensor_key)\n",
    "                if not sensor_id:\n",
    "                    logging.warning(f\"No registered sensor found for identifier: {sensor_key}. Skipping file.\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Read the file into a pandas DataFrame\n",
    "                df = pd.read_csv(\n",
    "                    filepath,\n",
    "                    sep='\\t',\n",
    "                    names=['timestamp', 'raw_reading', 'irradiance']\n",
    "                )\n",
    "\n",
    "                if df.empty:\n",
    "                    logging.warning(f\"Empty file: {filepath}\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Ensure timestamp is in UTC format\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "\n",
    "                # Add sensor ID to the DataFrame\n",
    "                df['irradiance_sensor_id'] = sensor_id\n",
    "\n",
    "                # Validate data if enabled\n",
    "                if validate:\n",
    "                    df, validation_stats = validate_irradiance_data(df)\n",
    "                    if df.empty:\n",
    "                        logging.warning(f\"All data filtered during validation: {filepath}\")\n",
    "                        stats['files_skipped'] += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "\n",
    "                # Check if last data point exists to avoid duplicates\n",
    "                last_timestamp = df['timestamp'].iloc[-1]\n",
    "                data_exists = check_existing_data(\n",
    "                    engine,\n",
    "                    IRRADIANCE_MEASUREMENT_TABLE,\n",
    "                    'irradiance_sensor_id',\n",
    "                    sensor_id,\n",
    "                    last_timestamp,\n",
    "                    id_field='timestamp'  # Explicitly specify timestamp as the id_field\n",
    "                )\n",
    "\n",
    "                if data_exists:\n",
    "                    logging.info(f\"Data already exists for {filepath}. Skipping file.\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                else:\n",
    "                    # Upload data in batches for large files\n",
    "                    total_rows = len(df)\n",
    "                    for i in range(0, total_rows, batch_size):\n",
    "                        batch_df = df.iloc[i:i+batch_size]\n",
    "                        batch_df.to_sql(\n",
    "                            IRRADIANCE_MEASUREMENT_TABLE,\n",
    "                            engine,\n",
    "                            if_exists='append',\n",
    "                            index=False\n",
    "                        )\n",
    "\n",
    "                    stats['rows_inserted'] += total_rows\n",
    "                    stats['files_processed'] += 1\n",
    "                    logging.info(f\"Successfully uploaded {total_rows} rows from {filepath}\")\n",
    "\n",
    "                # Clean up\n",
    "                del df\n",
    "                pbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {filepath}: {str(e)}\")\n",
    "                stats['files_error'] += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Calculate duration\n",
    "    stats['end_time'] = datetime.now(timezone.utc)\n",
    "    stats['duration_seconds'] = (stats['end_time'] - stats['start_time']).total_seconds()\n",
    "\n",
    "    logging.info(f\"Processing complete. Processed {stats['files_processed']} files, \"\n",
    "                 f\"skipped {stats['files_skipped']} files, \"\n",
    "                 f\"errors in {stats['files_error']} files. \"\n",
    "                 f\"Inserted {stats['rows_inserted']} data points in {stats['duration_seconds']:.2f} seconds.\")\n",
    "\n",
    "    return stats\n",
    "\n",
    "def process_temperature_files(root_dir, engine, pattern=TEMPERATURE_FILE_PATTERN, batch_size=BATCH_SIZE, validate=VALIDATION_CONFIG['enabled']):\n",
    "    \"\"\"\n",
    "    Process temperature data files and upload to database.\n",
    "    \"\"\"\n",
    "    # Statistics to return\n",
    "    stats = {\n",
    "        'files_processed': 0,\n",
    "        'files_skipped': 0,\n",
    "        'files_error': 0,\n",
    "        'rows_inserted': 0,\n",
    "        'start_time': datetime.now(timezone.utc),\n",
    "        'total_files': 0\n",
    "    }\n",
    "\n",
    "    # Convert to Path object for better path handling\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        logging.error(f\"Root directory does not exist: {root_dir}\")\n",
    "        return stats\n",
    "\n",
    "    # Compile the regex pattern for efficiency\n",
    "    pattern_compiled = re.compile(pattern)\n",
    "\n",
    "    # First, collect all matching filepaths\n",
    "    matching_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        path_parts = Path(dirpath).parts\n",
    "        if any(part.startswith(\"data\") for part in path_parts):\n",
    "            for filename in filenames:\n",
    "                filepath = Path(dirpath) / filename\n",
    "                if pattern_compiled.search(filename):\n",
    "                    matching_files.append(filepath)\n",
    "\n",
    "    stats['total_files'] = len(matching_files)\n",
    "    logging.info(f\"Found {len(matching_files)} temperature data files to process\")\n",
    "\n",
    "    # Create a mapping of sensor identifiers to database IDs\n",
    "    query = text(f\"\"\"SELECT temperature_sensor_id, sensor_identifier FROM {TEMPERATURE_SENSOR_TABLE}\"\"\")\n",
    "    sensor_mapping = {}\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        for row in result:\n",
    "            sensor_mapping[row.sensor_identifier] = row.temperature_sensor_id\n",
    "    \n",
    "    if not sensor_mapping:\n",
    "        logging.error(\"No temperature sensors registered in the database\")\n",
    "        return stats\n",
    "\n",
    "    # Process files with a progress bar\n",
    "    with tqdm(total=len(matching_files), desc=\"Processing Temperature Files\") as pbar:\n",
    "        for filepath in matching_files:\n",
    "            try:\n",
    "                # Extract sensor info from filename\n",
    "                match = pattern_compiled.search(filepath.name)\n",
    "                if not match:\n",
    "                    logging.warning(f\"Could not parse sensor info from filename: {filepath}\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                sensor_identifier = match.group(1)  # Extract the sensor ID from filename\n",
    "                \n",
    "                # Look up sensor ID from mapping\n",
    "                sensor_id = sensor_mapping.get(sensor_identifier)\n",
    "                if not sensor_id:\n",
    "                    logging.warning(f\"No registered sensor found for identifier: {sensor_identifier}. Skipping file.\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Read the file into a pandas DataFrame\n",
    "                df = pd.read_csv(\n",
    "                    filepath,\n",
    "                    sep='\\t',\n",
    "                    names=['timestamp', 'temperature']\n",
    "                )\n",
    "\n",
    "                if df.empty:\n",
    "                    logging.warning(f\"Empty file: {filepath}\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                # Ensure timestamp is in UTC format\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "\n",
    "                # Add sensor ID to the DataFrame\n",
    "                df['temperature_sensor_id'] = sensor_id\n",
    "\n",
    "                # Validate data if enabled\n",
    "                if validate:\n",
    "                    df, validation_stats = validate_temperature_data(df)\n",
    "                    if df.empty:\n",
    "                        logging.warning(f\"All data filtered during validation: {filepath}\")\n",
    "                        stats['files_skipped'] += 1\n",
    "                        pbar.update(1)\n",
    "                        continue\n",
    "\n",
    "                # Check if last data point exists to avoid duplicates\n",
    "                last_timestamp = df['timestamp'].iloc[-1]\n",
    "                data_exists = check_existing_data(\n",
    "                    engine,\n",
    "                    TEMPERATURE_MEASUREMENT_TABLE,\n",
    "                    'temperature_sensor_id',\n",
    "                    sensor_id,\n",
    "                    last_timestamp,\n",
    "                    id_field='timestamp'  # Explicitly specify timestamp as the id_field\n",
    "                )\n",
    "\n",
    "                if data_exists:\n",
    "                    logging.info(f\"Data already exists for {filepath}. Skipping file.\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                else:\n",
    "                    # Upload data in batches for large files\n",
    "                    total_rows = len(df)\n",
    "                    for i in range(0, total_rows, batch_size):\n",
    "                        batch_df = df.iloc[i:i+batch_size]\n",
    "                        batch_df.to_sql(\n",
    "                            TEMPERATURE_MEASUREMENT_TABLE,\n",
    "                            engine,\n",
    "                            if_exists='append',\n",
    "                            index=False\n",
    "                        )\n",
    "\n",
    "                    stats['rows_inserted'] += total_rows\n",
    "                    stats['files_processed'] += 1\n",
    "                    logging.info(f\"Successfully uploaded {total_rows} rows from {filepath}\")\n",
    "\n",
    "                # Clean up\n",
    "                del df\n",
    "                pbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {filepath}: {str(e)}\")\n",
    "                stats['files_error'] += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Calculate duration\n",
    "    stats['end_time'] = datetime.now(timezone.utc)\n",
    "    stats['duration_seconds'] = (stats['end_time'] - stats['start_time']).total_seconds()\n",
    "\n",
    "    logging.info(f\"Processing complete. Processed {stats['files_processed']} files, \"\n",
    "                 f\"skipped {stats['files_skipped']} files, \"\n",
    "                 f\"errors in {stats['files_error']} files. \"\n",
    "                 f\"Inserted {stats['rows_inserted']} data points in {stats['duration_seconds']:.2f} seconds.\")\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8940b",
   "metadata": {},
   "source": [
    "## 6. Execute the Data Upload Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03115d31-ab12-4d9e-81ba-216619bdf396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:02:03,654 - INFO - Database connection successful: localhost:5432/perocube\n",
      "2025-05-15 16:02:03,655 - INFO - Database connection established successfully\n",
      "2025-05-15 16:02:03,655 - INFO - Database connection established successfully\n"
     ]
    }
   ],
   "source": [
    "# Create database connection\n",
    "try:\n",
    "    engine = create_db_connection()\n",
    "    logging.info(\"Database connection established successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to connect to database: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b78a4e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:02:03,684 - INFO - Schema changes applied successfully\n"
     ]
    }
   ],
   "source": [
    "# Execute schema changes to add sensor identifier columns\n",
    "schema_changes = text(\"\"\"\n",
    "-- Add columns to irradiance_sensor table\n",
    "ALTER TABLE irradiance_sensor \n",
    "ADD COLUMN IF NOT EXISTS sensor_identifier VARCHAR(50),\n",
    "ADD COLUMN IF NOT EXISTS channel INTEGER;\n",
    "\n",
    "-- Add columns to temperature_sensor table\n",
    "ALTER TABLE temperature_sensor \n",
    "ADD COLUMN IF NOT EXISTS sensor_identifier VARCHAR(50);\n",
    "\n",
    "-- Add unique constraints\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS irr_sensor_identifier_channel_idx \n",
    "ON irradiance_sensor (sensor_identifier, channel);\n",
    "\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS temp_sensor_identifier_idx \n",
    "ON temperature_sensor (sensor_identifier);\n",
    "\"\"\")\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(schema_changes)\n",
    "        conn.commit()\n",
    "        logging.info(\"Schema changes applied successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to apply schema changes: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0b73fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:02:03,755 - INFO - Found 0 unique irradiance sensors\n",
      "2025-05-15 16:02:03,756 - INFO - Registered 0 new irradiance sensors\n",
      "2025-05-15 16:02:03,756 - INFO - Found 2 existing irradiance sensors\n",
      "2025-05-15 16:02:03,756 - INFO - Registered 0 new irradiance sensors\n",
      "2025-05-15 16:02:03,756 - INFO - Found 2 existing irradiance sensors\n",
      "2025-05-15 16:02:03,762 - INFO - Found 0 unique temperature sensors\n",
      "2025-05-15 16:02:03,763 - INFO - Registered 0 new temperature sensors\n",
      "2025-05-15 16:02:03,763 - INFO - Found 5 existing temperature sensors\n",
      "2025-05-15 16:02:03,762 - INFO - Found 0 unique temperature sensors\n",
      "2025-05-15 16:02:03,763 - INFO - Registered 0 new temperature sensors\n",
      "2025-05-15 16:02:03,763 - INFO - Found 5 existing temperature sensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sensor registration from directory: ../../sample_data/datasets/PeroCube-sample-data\n",
      "\n",
      "1. Registering irradiance sensors...\n",
      "\n",
      "2. Registering temperature sensors...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Register sensors in the database\n",
    "print(f\"Starting sensor registration from directory: {ROOT_DIRECTORY}\")\n",
    "print(\"\\n1. Registering irradiance sensors...\")\n",
    "irr_sensor_stats = register_irradiance_sensors(ROOT_DIRECTORY, engine)\n",
    "\n",
    "print(\"\\n2. Registering temperature sensors...\")\n",
    "temp_sensor_stats = register_temperature_sensors(ROOT_DIRECTORY, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2f6576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registered irradiance sensors in database:\n",
      "  - Sensor: PT-104_1 -> 7c9b9624-a1f5-4f53-b007-7a0e80d32b93\n",
      "  - Sensor: PT-104_3 -> 46688ea2-1e86-4120-9693-7836d532e155\n",
      "\n",
      "Total registered irradiance sensors: 2\n",
      "\n",
      "Example file names that will be processed:\n",
      "  - PT-104_channel_01.txt\n",
      "    Would use key: PT-104_1\n",
      "    Sensor exists in DB: True\n",
      "  - PT-104_channel_03.txt\n",
      "    Would use key: PT-104_3\n",
      "    Sensor exists in DB: True\n",
      "  - PT-104_channel_01.txt\n",
      "    Would use key: PT-104_1\n",
      "    Sensor exists in DB: True\n"
     ]
    }
   ],
   "source": [
    "# Debug cell to check registered sensors and their keys\n",
    "print(\"\\nRegistered irradiance sensors in database:\")\n",
    "query = text(f\"\"\"SELECT sensor_identifier, channel, irradiance_sensor_id FROM {IRRADIANCE_SENSOR_TABLE}\"\"\")\n",
    "sensor_mapping = {}\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(query)\n",
    "    for idx, row in enumerate(result):\n",
    "        sensor_key = f\"{row.sensor_identifier}_{row.channel}\"\n",
    "        sensor_mapping[sensor_key] = row.irradiance_sensor_id\n",
    "        # Print first few rows to verify format\n",
    "        if idx < 5:\n",
    "            print(f\"  - Sensor: {sensor_key} -> {row.irradiance_sensor_id}\")\n",
    "            \n",
    "print(f\"\\nTotal registered irradiance sensors: {len(sensor_mapping)}\")\n",
    "print(\"\\nExample file names that will be processed:\")\n",
    "\n",
    "# Show some example filenames to compare with registered keys\n",
    "import glob\n",
    "example_files = glob.glob(f\"{ROOT_DIRECTORY}/**/PT-*.txt\", recursive=True)[:3]\n",
    "for file in example_files:\n",
    "    print(f\"  - {os.path.basename(file)}\")\n",
    "    # Extract sensor info using the same pattern\n",
    "    match = re.search(IRRADIANCE_FILE_PATTERN, os.path.basename(file))\n",
    "    if match:\n",
    "        sensor_number = match.group(1)  \n",
    "        channel = int(match.group(2))\n",
    "        sensor_identifier = f\"PT-{sensor_number}\"\n",
    "        sensor_key = f\"{sensor_identifier}_{channel}\"  # Using the same key format as in processing\n",
    "        print(f\"    Would use key: {sensor_key}\")\n",
    "        print(f\"    Sensor exists in DB: {sensor_key in sensor_mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bd05b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:02:03,899 - INFO - Found 35 irradiance data files to process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation Configuration:\n",
      "- Validation enabled: False\n",
      "- Remove NaN values: True\n",
      "\n",
      "Physical value validation is disabled\n",
      "\n",
      "Data Validation Configuration:\n",
      "- Validation enabled: False\n",
      "- Remove NaN values: True\n",
      "\n",
      "Physical value validation is disabled\n",
      "\n",
      "3. Processing irradiance data files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02bcc7c6390490aa8f6276b8a184127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Irradiance Files:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:02:04,358 - INFO - Successfully uploaded 10714 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240319/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:04,758 - INFO - Successfully uploaded 10714 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240319/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:04,758 - INFO - Successfully uploaded 10714 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240319/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:35,197 - INFO - Successfully uploaded 7552 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240222/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:35,197 - INFO - Successfully uploaded 7552 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240222/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:35,501 - INFO - Successfully uploaded 7552 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240222/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:35,501 - INFO - Successfully uploaded 7552 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240222/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:41,693 - INFO - Successfully uploaded 179220 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240220/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:41,693 - INFO - Successfully uploaded 179220 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240220/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:47,668 - INFO - Successfully uploaded 179220 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240220/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:47,668 - INFO - Successfully uploaded 179220 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240220/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:48,292 - ERROR - Error processing ../../sample_data/datasets/PeroCube-sample-data/data_20240514/data/PT-104_channel_01.txt: (psycopg2.errors.NotNullViolation) NULL value in column \"timestamp\" violates not-null constraint\n",
      "HINT:  Columns used for time partitioning cannot be NULL.\n",
      "\n",
      "[SQL: INSERT INTO irradiance_measurement (timestamp, raw_reading, irradiance, irradiance_sensor_id) VALUES (%(timestamp__0)s, %(raw_reading__0)s, %(irradiance__0)s, %(irradiance_sensor_id__0)s), (%(timestamp__1)s, %(raw_reading__1)s, %(irradiance__1)s, %(i ... 95309 characters truncated ... 8)s), (%(timestamp__999)s, %(raw_reading__999)s, %(irradiance__999)s, %(irradiance_sensor_id__999)s)]\n",
      "[parameters: {'timestamp__0': datetime.datetime(2024, 4, 24, 20, 57, 59, tzinfo=datetime.timezone.utc), 'irradiance__0': -2.251, 'raw_reading__0': -107844, 'irradiance_sensor_id__0': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__1': datetime.datetime(2024, 4, 24, 20, 58, 29, tzinfo=datetime.timezone.utc), 'irradiance__1': -2.238, 'raw_reading__1': -107211, 'irradiance_sensor_id__1': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__2': datetime.datetime(2024, 4, 24, 20, 58, 59, tzinfo=datetime.timezone.utc), 'irradiance__2': -2.234, 'raw_reading__2': -107030, 'irradiance_sensor_id__2': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__3': datetime.datetime(2024, 4, 24, 20, 59, 29, tzinfo=datetime.timezone.utc), 'irradiance__3': -2.242, 'raw_reading__3': -107398, 'irradiance_sensor_id__3': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__4': datetime.datetime(2024, 4, 24, 20, 59, 59, tzinfo=datetime.timezone.utc), 'irradiance__4': -2.229, 'raw_reading__4': -106782, 'irradiance_sensor_id__4': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__5': datetime.datetime(2024, 4, 24, 21, 0, 29, tzinfo=datetime.timezone.utc), 'irradiance__5': -2.226, 'raw_reading__5': -106646, 'irradiance_sensor_id__5': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__6': datetime.datetime(2024, 4, 24, 21, 0, 59, tzinfo=datetime.timezone.utc), 'irradiance__6': -2.233, 'raw_reading__6': -106953, 'irradiance_sensor_id__6': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__7': datetime.datetime(2024, 4, 24, 21, 1, 29, tzinfo=datetime.timezone.utc), 'irradiance__7': -2.233, 'raw_reading__7': -106963, 'irradiance_sensor_id__7': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__8': datetime.datetime(2024, 4, 24, 21, 1, 59, tzinfo=datetime.timezone.utc), 'irradiance__8': -2.227, 'raw_reading__8': -106668, 'irradiance_sensor_id__8': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__9': datetime.datetime(2024, 4, 24, 21, 2, 29, tzinfo=datetime.timezone.utc), 'irradiance__9': -2.227, 'raw_reading__9': -106670, 'irradiance_sensor_id__9': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__10': datetime.datetime(2024, 4, 24, 21, 2, 59, tzinfo=datetime.timezone.utc), 'irradiance__10': -2.227, 'raw_reading__10': -106651, 'irradiance_sensor_id__10': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__11': datetime.datetime(2024, 4, 24, 21, 3, 29, tzinfo=datetime.timezone.utc), 'irradiance__11': -2.236, 'raw_reading__11': -107093, 'irradiance_sensor_id__11': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__12': datetime.datetime(2024, 4, 24, 21, 3, 59, tzinfo=datetime.timezone.utc), 'irradiance__12': -2.244 ... 3900 parameters truncated ... 'raw_reading__987': 10315279, 'irradiance_sensor_id__987': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__988': datetime.datetime(2024, 4, 25, 12, 34, 40, tzinfo=datetime.timezone.utc), 'irradiance__988': 195.59, 'raw_reading__988': 9368756, 'irradiance_sensor_id__988': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__989': datetime.datetime(2024, 4, 25, 12, 35, 10, tzinfo=datetime.timezone.utc), 'irradiance__989': 180.17, 'raw_reading__989': 8630145, 'irradiance_sensor_id__989': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__990': datetime.datetime(2024, 4, 25, 12, 35, 40, tzinfo=datetime.timezone.utc), 'irradiance__990': 169.965, 'raw_reading__990': 8141310, 'irradiance_sensor_id__990': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__991': datetime.datetime(2024, 4, 25, 12, 36, 10, tzinfo=datetime.timezone.utc), 'irradiance__991': 163.837, 'raw_reading__991': 7847787, 'irradiance_sensor_id__991': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__992': datetime.datetime(2024, 4, 25, 12, 36, 40, tzinfo=datetime.timezone.utc), 'irradiance__992': 161.818, 'raw_reading__992': 7751061, 'irradiance_sensor_id__992': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__993': datetime.datetime(2024, 4, 25, 12, 37, 10, tzinfo=datetime.timezone.utc), 'irradiance__993': 163.263, 'raw_reading__993': 7820316, 'irradiance_sensor_id__993': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__994': datetime.datetime(2024, 4, 25, 12, 37, 40, tzinfo=datetime.timezone.utc), 'irradiance__994': 166.957, 'raw_reading__994': 7997260, 'irradiance_sensor_id__994': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__995': datetime.datetime(2024, 4, 25, 12, 38, 10, tzinfo=datetime.timezone.utc), 'irradiance__995': 173.44, 'raw_reading__995': 8307783, 'irradiance_sensor_id__995': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__996': datetime.datetime(2024, 4, 25, 12, 38, 40, tzinfo=datetime.timezone.utc), 'irradiance__996': 182.129, 'raw_reading__996': 8723989, 'irradiance_sensor_id__996': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__997': datetime.datetime(2024, 4, 25, 12, 39, 10, tzinfo=datetime.timezone.utc), 'irradiance__997': 192.058, 'raw_reading__997': 9199563, 'irradiance_sensor_id__997': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__998': datetime.datetime(2024, 4, 25, 12, 39, 40, tzinfo=datetime.timezone.utc), 'irradiance__998': 203.141, 'raw_reading__998': 9730471, 'irradiance_sensor_id__998': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__999': datetime.datetime(2024, 4, 25, 12, 40, 10, tzinfo=datetime.timezone.utc), 'irradiance__999': 215.668, 'raw_reading__999': 10330480, 'irradiance_sensor_id__999': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93')}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-05-15 16:02:48,292 - ERROR - Error processing ../../sample_data/datasets/PeroCube-sample-data/data_20240514/data/PT-104_channel_01.txt: (psycopg2.errors.NotNullViolation) NULL value in column \"timestamp\" violates not-null constraint\n",
      "HINT:  Columns used for time partitioning cannot be NULL.\n",
      "\n",
      "[SQL: INSERT INTO irradiance_measurement (timestamp, raw_reading, irradiance, irradiance_sensor_id) VALUES (%(timestamp__0)s, %(raw_reading__0)s, %(irradiance__0)s, %(irradiance_sensor_id__0)s), (%(timestamp__1)s, %(raw_reading__1)s, %(irradiance__1)s, %(i ... 95309 characters truncated ... 8)s), (%(timestamp__999)s, %(raw_reading__999)s, %(irradiance__999)s, %(irradiance_sensor_id__999)s)]\n",
      "[parameters: {'timestamp__0': datetime.datetime(2024, 4, 24, 20, 57, 59, tzinfo=datetime.timezone.utc), 'irradiance__0': -2.251, 'raw_reading__0': -107844, 'irradiance_sensor_id__0': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__1': datetime.datetime(2024, 4, 24, 20, 58, 29, tzinfo=datetime.timezone.utc), 'irradiance__1': -2.238, 'raw_reading__1': -107211, 'irradiance_sensor_id__1': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__2': datetime.datetime(2024, 4, 24, 20, 58, 59, tzinfo=datetime.timezone.utc), 'irradiance__2': -2.234, 'raw_reading__2': -107030, 'irradiance_sensor_id__2': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__3': datetime.datetime(2024, 4, 24, 20, 59, 29, tzinfo=datetime.timezone.utc), 'irradiance__3': -2.242, 'raw_reading__3': -107398, 'irradiance_sensor_id__3': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__4': datetime.datetime(2024, 4, 24, 20, 59, 59, tzinfo=datetime.timezone.utc), 'irradiance__4': -2.229, 'raw_reading__4': -106782, 'irradiance_sensor_id__4': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__5': datetime.datetime(2024, 4, 24, 21, 0, 29, tzinfo=datetime.timezone.utc), 'irradiance__5': -2.226, 'raw_reading__5': -106646, 'irradiance_sensor_id__5': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__6': datetime.datetime(2024, 4, 24, 21, 0, 59, tzinfo=datetime.timezone.utc), 'irradiance__6': -2.233, 'raw_reading__6': -106953, 'irradiance_sensor_id__6': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__7': datetime.datetime(2024, 4, 24, 21, 1, 29, tzinfo=datetime.timezone.utc), 'irradiance__7': -2.233, 'raw_reading__7': -106963, 'irradiance_sensor_id__7': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__8': datetime.datetime(2024, 4, 24, 21, 1, 59, tzinfo=datetime.timezone.utc), 'irradiance__8': -2.227, 'raw_reading__8': -106668, 'irradiance_sensor_id__8': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__9': datetime.datetime(2024, 4, 24, 21, 2, 29, tzinfo=datetime.timezone.utc), 'irradiance__9': -2.227, 'raw_reading__9': -106670, 'irradiance_sensor_id__9': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__10': datetime.datetime(2024, 4, 24, 21, 2, 59, tzinfo=datetime.timezone.utc), 'irradiance__10': -2.227, 'raw_reading__10': -106651, 'irradiance_sensor_id__10': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__11': datetime.datetime(2024, 4, 24, 21, 3, 29, tzinfo=datetime.timezone.utc), 'irradiance__11': -2.236, 'raw_reading__11': -107093, 'irradiance_sensor_id__11': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__12': datetime.datetime(2024, 4, 24, 21, 3, 59, tzinfo=datetime.timezone.utc), 'irradiance__12': -2.244 ... 3900 parameters truncated ... 'raw_reading__987': 10315279, 'irradiance_sensor_id__987': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__988': datetime.datetime(2024, 4, 25, 12, 34, 40, tzinfo=datetime.timezone.utc), 'irradiance__988': 195.59, 'raw_reading__988': 9368756, 'irradiance_sensor_id__988': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__989': datetime.datetime(2024, 4, 25, 12, 35, 10, tzinfo=datetime.timezone.utc), 'irradiance__989': 180.17, 'raw_reading__989': 8630145, 'irradiance_sensor_id__989': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__990': datetime.datetime(2024, 4, 25, 12, 35, 40, tzinfo=datetime.timezone.utc), 'irradiance__990': 169.965, 'raw_reading__990': 8141310, 'irradiance_sensor_id__990': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__991': datetime.datetime(2024, 4, 25, 12, 36, 10, tzinfo=datetime.timezone.utc), 'irradiance__991': 163.837, 'raw_reading__991': 7847787, 'irradiance_sensor_id__991': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__992': datetime.datetime(2024, 4, 25, 12, 36, 40, tzinfo=datetime.timezone.utc), 'irradiance__992': 161.818, 'raw_reading__992': 7751061, 'irradiance_sensor_id__992': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__993': datetime.datetime(2024, 4, 25, 12, 37, 10, tzinfo=datetime.timezone.utc), 'irradiance__993': 163.263, 'raw_reading__993': 7820316, 'irradiance_sensor_id__993': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__994': datetime.datetime(2024, 4, 25, 12, 37, 40, tzinfo=datetime.timezone.utc), 'irradiance__994': 166.957, 'raw_reading__994': 7997260, 'irradiance_sensor_id__994': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__995': datetime.datetime(2024, 4, 25, 12, 38, 10, tzinfo=datetime.timezone.utc), 'irradiance__995': 173.44, 'raw_reading__995': 8307783, 'irradiance_sensor_id__995': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__996': datetime.datetime(2024, 4, 25, 12, 38, 40, tzinfo=datetime.timezone.utc), 'irradiance__996': 182.129, 'raw_reading__996': 8723989, 'irradiance_sensor_id__996': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__997': datetime.datetime(2024, 4, 25, 12, 39, 10, tzinfo=datetime.timezone.utc), 'irradiance__997': 192.058, 'raw_reading__997': 9199563, 'irradiance_sensor_id__997': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__998': datetime.datetime(2024, 4, 25, 12, 39, 40, tzinfo=datetime.timezone.utc), 'irradiance__998': 203.141, 'raw_reading__998': 9730471, 'irradiance_sensor_id__998': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__999': datetime.datetime(2024, 4, 25, 12, 40, 10, tzinfo=datetime.timezone.utc), 'irradiance__999': 215.668, 'raw_reading__999': 10330480, 'irradiance_sensor_id__999': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93')}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-05-15 16:02:48,962 - ERROR - Error processing ../../sample_data/datasets/PeroCube-sample-data/data_20240514/data/PT-104_channel_03.txt: (psycopg2.errors.NotNullViolation) NULL value in column \"timestamp\" violates not-null constraint\n",
      "HINT:  Columns used for time partitioning cannot be NULL.\n",
      "\n",
      "[SQL: INSERT INTO irradiance_measurement (timestamp, raw_reading, irradiance, irradiance_sensor_id) VALUES (%(timestamp__0)s, %(raw_reading__0)s, %(irradiance__0)s, %(irradiance_sensor_id__0)s), (%(timestamp__1)s, %(raw_reading__1)s, %(irradiance__1)s, %(i ... 95309 characters truncated ... 8)s), (%(timestamp__999)s, %(raw_reading__999)s, %(irradiance__999)s, %(irradiance_sensor_id__999)s)]\n",
      "[parameters: {'timestamp__0': datetime.datetime(2024, 4, 24, 20, 57, 59, tzinfo=datetime.timezone.utc), 'irradiance__0': -2.201, 'raw_reading__0': -105444, 'irradiance_sensor_id__0': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__1': datetime.datetime(2024, 4, 24, 20, 58, 29, tzinfo=datetime.timezone.utc), 'irradiance__1': -2.197, 'raw_reading__1': -105248, 'irradiance_sensor_id__1': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__2': datetime.datetime(2024, 4, 24, 20, 58, 59, tzinfo=datetime.timezone.utc), 'irradiance__2': -2.198, 'raw_reading__2': -105302, 'irradiance_sensor_id__2': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__3': datetime.datetime(2024, 4, 24, 20, 59, 29, tzinfo=datetime.timezone.utc), 'irradiance__3': -2.188, 'raw_reading__3': -104807, 'irradiance_sensor_id__3': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__4': datetime.datetime(2024, 4, 24, 20, 59, 59, tzinfo=datetime.timezone.utc), 'irradiance__4': -2.195, 'raw_reading__4': -105134, 'irradiance_sensor_id__4': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__5': datetime.datetime(2024, 4, 24, 21, 0, 29, tzinfo=datetime.timezone.utc), 'irradiance__5': -2.186, 'raw_reading__5': -104731, 'irradiance_sensor_id__5': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__6': datetime.datetime(2024, 4, 24, 21, 0, 59, tzinfo=datetime.timezone.utc), 'irradiance__6': -2.19, 'raw_reading__6': -104914, 'irradiance_sensor_id__6': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__7': datetime.datetime(2024, 4, 24, 21, 1, 29, tzinfo=datetime.timezone.utc), 'irradiance__7': -2.187, 'raw_reading__7': -104734, 'irradiance_sensor_id__7': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__8': datetime.datetime(2024, 4, 24, 21, 1, 59, tzinfo=datetime.timezone.utc), 'irradiance__8': -2.182, 'raw_reading__8': -104505, 'irradiance_sensor_id__8': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__9': datetime.datetime(2024, 4, 24, 21, 2, 29, tzinfo=datetime.timezone.utc), 'irradiance__9': -2.181, 'raw_reading__9': -104493, 'irradiance_sensor_id__9': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__10': datetime.datetime(2024, 4, 24, 21, 2, 59, tzinfo=datetime.timezone.utc), 'irradiance__10': -2.183, 'raw_reading__10': -104547, 'irradiance_sensor_id__10': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__11': datetime.datetime(2024, 4, 24, 21, 3, 29, tzinfo=datetime.timezone.utc), 'irradiance__11': -2.187, 'raw_reading__11': -104759, 'irradiance_sensor_id__11': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__12': datetime.datetime(2024, 4, 24, 21, 3, 59, tzinfo=datetime.timezone.utc), 'irradiance__12': -2.187 ... 3900 parameters truncated ... 'raw_reading__987': 12000458, 'irradiance_sensor_id__987': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__988': datetime.datetime(2024, 4, 25, 12, 34, 40, tzinfo=datetime.timezone.utc), 'irradiance__988': 226.624, 'raw_reading__988': 10855295, 'irradiance_sensor_id__988': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__989': datetime.datetime(2024, 4, 25, 12, 35, 10, tzinfo=datetime.timezone.utc), 'irradiance__989': 209.648, 'raw_reading__989': 10042162, 'irradiance_sensor_id__989': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__990': datetime.datetime(2024, 4, 25, 12, 35, 40, tzinfo=datetime.timezone.utc), 'irradiance__990': 197.878, 'raw_reading__990': 9478335, 'irradiance_sensor_id__990': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__991': datetime.datetime(2024, 4, 25, 12, 36, 10, tzinfo=datetime.timezone.utc), 'irradiance__991': 190.676, 'raw_reading__991': 9133382, 'irradiance_sensor_id__991': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__992': datetime.datetime(2024, 4, 25, 12, 36, 40, tzinfo=datetime.timezone.utc), 'irradiance__992': 188.66, 'raw_reading__992': 9036836, 'irradiance_sensor_id__992': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__993': datetime.datetime(2024, 4, 25, 12, 37, 10, tzinfo=datetime.timezone.utc), 'irradiance__993': 190.436, 'raw_reading__993': 9121878, 'irradiance_sensor_id__993': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__994': datetime.datetime(2024, 4, 25, 12, 37, 40, tzinfo=datetime.timezone.utc), 'irradiance__994': 195.137, 'raw_reading__994': 9347048, 'irradiance_sensor_id__994': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__995': datetime.datetime(2024, 4, 25, 12, 38, 10, tzinfo=datetime.timezone.utc), 'irradiance__995': 202.497, 'raw_reading__995': 9699592, 'irradiance_sensor_id__995': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__996': datetime.datetime(2024, 4, 25, 12, 38, 40, tzinfo=datetime.timezone.utc), 'irradiance__996': 212.722, 'raw_reading__996': 10189368, 'irradiance_sensor_id__996': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__997': datetime.datetime(2024, 4, 25, 12, 39, 10, tzinfo=datetime.timezone.utc), 'irradiance__997': 225.004, 'raw_reading__997': 10777688, 'irradiance_sensor_id__997': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__998': datetime.datetime(2024, 4, 25, 12, 39, 40, tzinfo=datetime.timezone.utc), 'irradiance__998': 238.191, 'raw_reading__998': 11409354, 'irradiance_sensor_id__998': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__999': datetime.datetime(2024, 4, 25, 12, 40, 10, tzinfo=datetime.timezone.utc), 'irradiance__999': 252.442, 'raw_reading__999': 12091966, 'irradiance_sensor_id__999': UUID('46688ea2-1e86-4120-9693-7836d532e155')}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-05-15 16:02:48,962 - ERROR - Error processing ../../sample_data/datasets/PeroCube-sample-data/data_20240514/data/PT-104_channel_03.txt: (psycopg2.errors.NotNullViolation) NULL value in column \"timestamp\" violates not-null constraint\n",
      "HINT:  Columns used for time partitioning cannot be NULL.\n",
      "\n",
      "[SQL: INSERT INTO irradiance_measurement (timestamp, raw_reading, irradiance, irradiance_sensor_id) VALUES (%(timestamp__0)s, %(raw_reading__0)s, %(irradiance__0)s, %(irradiance_sensor_id__0)s), (%(timestamp__1)s, %(raw_reading__1)s, %(irradiance__1)s, %(i ... 95309 characters truncated ... 8)s), (%(timestamp__999)s, %(raw_reading__999)s, %(irradiance__999)s, %(irradiance_sensor_id__999)s)]\n",
      "[parameters: {'timestamp__0': datetime.datetime(2024, 4, 24, 20, 57, 59, tzinfo=datetime.timezone.utc), 'irradiance__0': -2.201, 'raw_reading__0': -105444, 'irradiance_sensor_id__0': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__1': datetime.datetime(2024, 4, 24, 20, 58, 29, tzinfo=datetime.timezone.utc), 'irradiance__1': -2.197, 'raw_reading__1': -105248, 'irradiance_sensor_id__1': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__2': datetime.datetime(2024, 4, 24, 20, 58, 59, tzinfo=datetime.timezone.utc), 'irradiance__2': -2.198, 'raw_reading__2': -105302, 'irradiance_sensor_id__2': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__3': datetime.datetime(2024, 4, 24, 20, 59, 29, tzinfo=datetime.timezone.utc), 'irradiance__3': -2.188, 'raw_reading__3': -104807, 'irradiance_sensor_id__3': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__4': datetime.datetime(2024, 4, 24, 20, 59, 59, tzinfo=datetime.timezone.utc), 'irradiance__4': -2.195, 'raw_reading__4': -105134, 'irradiance_sensor_id__4': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__5': datetime.datetime(2024, 4, 24, 21, 0, 29, tzinfo=datetime.timezone.utc), 'irradiance__5': -2.186, 'raw_reading__5': -104731, 'irradiance_sensor_id__5': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__6': datetime.datetime(2024, 4, 24, 21, 0, 59, tzinfo=datetime.timezone.utc), 'irradiance__6': -2.19, 'raw_reading__6': -104914, 'irradiance_sensor_id__6': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__7': datetime.datetime(2024, 4, 24, 21, 1, 29, tzinfo=datetime.timezone.utc), 'irradiance__7': -2.187, 'raw_reading__7': -104734, 'irradiance_sensor_id__7': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__8': datetime.datetime(2024, 4, 24, 21, 1, 59, tzinfo=datetime.timezone.utc), 'irradiance__8': -2.182, 'raw_reading__8': -104505, 'irradiance_sensor_id__8': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__9': datetime.datetime(2024, 4, 24, 21, 2, 29, tzinfo=datetime.timezone.utc), 'irradiance__9': -2.181, 'raw_reading__9': -104493, 'irradiance_sensor_id__9': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__10': datetime.datetime(2024, 4, 24, 21, 2, 59, tzinfo=datetime.timezone.utc), 'irradiance__10': -2.183, 'raw_reading__10': -104547, 'irradiance_sensor_id__10': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__11': datetime.datetime(2024, 4, 24, 21, 3, 29, tzinfo=datetime.timezone.utc), 'irradiance__11': -2.187, 'raw_reading__11': -104759, 'irradiance_sensor_id__11': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__12': datetime.datetime(2024, 4, 24, 21, 3, 59, tzinfo=datetime.timezone.utc), 'irradiance__12': -2.187 ... 3900 parameters truncated ... 'raw_reading__987': 12000458, 'irradiance_sensor_id__987': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__988': datetime.datetime(2024, 4, 25, 12, 34, 40, tzinfo=datetime.timezone.utc), 'irradiance__988': 226.624, 'raw_reading__988': 10855295, 'irradiance_sensor_id__988': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__989': datetime.datetime(2024, 4, 25, 12, 35, 10, tzinfo=datetime.timezone.utc), 'irradiance__989': 209.648, 'raw_reading__989': 10042162, 'irradiance_sensor_id__989': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__990': datetime.datetime(2024, 4, 25, 12, 35, 40, tzinfo=datetime.timezone.utc), 'irradiance__990': 197.878, 'raw_reading__990': 9478335, 'irradiance_sensor_id__990': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__991': datetime.datetime(2024, 4, 25, 12, 36, 10, tzinfo=datetime.timezone.utc), 'irradiance__991': 190.676, 'raw_reading__991': 9133382, 'irradiance_sensor_id__991': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__992': datetime.datetime(2024, 4, 25, 12, 36, 40, tzinfo=datetime.timezone.utc), 'irradiance__992': 188.66, 'raw_reading__992': 9036836, 'irradiance_sensor_id__992': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__993': datetime.datetime(2024, 4, 25, 12, 37, 10, tzinfo=datetime.timezone.utc), 'irradiance__993': 190.436, 'raw_reading__993': 9121878, 'irradiance_sensor_id__993': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__994': datetime.datetime(2024, 4, 25, 12, 37, 40, tzinfo=datetime.timezone.utc), 'irradiance__994': 195.137, 'raw_reading__994': 9347048, 'irradiance_sensor_id__994': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__995': datetime.datetime(2024, 4, 25, 12, 38, 10, tzinfo=datetime.timezone.utc), 'irradiance__995': 202.497, 'raw_reading__995': 9699592, 'irradiance_sensor_id__995': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__996': datetime.datetime(2024, 4, 25, 12, 38, 40, tzinfo=datetime.timezone.utc), 'irradiance__996': 212.722, 'raw_reading__996': 10189368, 'irradiance_sensor_id__996': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__997': datetime.datetime(2024, 4, 25, 12, 39, 10, tzinfo=datetime.timezone.utc), 'irradiance__997': 225.004, 'raw_reading__997': 10777688, 'irradiance_sensor_id__997': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__998': datetime.datetime(2024, 4, 25, 12, 39, 40, tzinfo=datetime.timezone.utc), 'irradiance__998': 238.191, 'raw_reading__998': 11409354, 'irradiance_sensor_id__998': UUID('46688ea2-1e86-4120-9693-7836d532e155'), 'timestamp__999': datetime.datetime(2024, 4, 25, 12, 40, 10, tzinfo=datetime.timezone.utc), 'irradiance__999': 252.442, 'raw_reading__999': 12091966, 'irradiance_sensor_id__999': UUID('46688ea2-1e86-4120-9693-7836d532e155')}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-05-15 16:02:49,633 - ERROR - Error processing ../../sample_data/datasets/PeroCube-sample-data/data_20240514/data/.ipynb_checkpoints/PT-104_channel_01-checkpoint.txt: (psycopg2.errors.NotNullViolation) NULL value in column \"timestamp\" violates not-null constraint\n",
      "HINT:  Columns used for time partitioning cannot be NULL.\n",
      "\n",
      "[SQL: INSERT INTO irradiance_measurement (timestamp, raw_reading, irradiance, irradiance_sensor_id) VALUES (%(timestamp__0)s, %(raw_reading__0)s, %(irradiance__0)s, %(irradiance_sensor_id__0)s), (%(timestamp__1)s, %(raw_reading__1)s, %(irradiance__1)s, %(i ... 95309 characters truncated ... 8)s), (%(timestamp__999)s, %(raw_reading__999)s, %(irradiance__999)s, %(irradiance_sensor_id__999)s)]\n",
      "[parameters: {'timestamp__0': datetime.datetime(2024, 4, 24, 20, 57, 59, tzinfo=datetime.timezone.utc), 'irradiance__0': -2.251, 'raw_reading__0': -107844, 'irradiance_sensor_id__0': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__1': datetime.datetime(2024, 4, 24, 20, 58, 29, tzinfo=datetime.timezone.utc), 'irradiance__1': -2.238, 'raw_reading__1': -107211, 'irradiance_sensor_id__1': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__2': datetime.datetime(2024, 4, 24, 20, 58, 59, tzinfo=datetime.timezone.utc), 'irradiance__2': -2.234, 'raw_reading__2': -107030, 'irradiance_sensor_id__2': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__3': datetime.datetime(2024, 4, 24, 20, 59, 29, tzinfo=datetime.timezone.utc), 'irradiance__3': -2.242, 'raw_reading__3': -107398, 'irradiance_sensor_id__3': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__4': datetime.datetime(2024, 4, 24, 20, 59, 59, tzinfo=datetime.timezone.utc), 'irradiance__4': -2.229, 'raw_reading__4': -106782, 'irradiance_sensor_id__4': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__5': datetime.datetime(2024, 4, 24, 21, 0, 29, tzinfo=datetime.timezone.utc), 'irradiance__5': -2.226, 'raw_reading__5': -106646, 'irradiance_sensor_id__5': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__6': datetime.datetime(2024, 4, 24, 21, 0, 59, tzinfo=datetime.timezone.utc), 'irradiance__6': -2.233, 'raw_reading__6': -106953, 'irradiance_sensor_id__6': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__7': datetime.datetime(2024, 4, 24, 21, 1, 29, tzinfo=datetime.timezone.utc), 'irradiance__7': -2.233, 'raw_reading__7': -106963, 'irradiance_sensor_id__7': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__8': datetime.datetime(2024, 4, 24, 21, 1, 59, tzinfo=datetime.timezone.utc), 'irradiance__8': -2.227, 'raw_reading__8': -106668, 'irradiance_sensor_id__8': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__9': datetime.datetime(2024, 4, 24, 21, 2, 29, tzinfo=datetime.timezone.utc), 'irradiance__9': -2.227, 'raw_reading__9': -106670, 'irradiance_sensor_id__9': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__10': datetime.datetime(2024, 4, 24, 21, 2, 59, tzinfo=datetime.timezone.utc), 'irradiance__10': -2.227, 'raw_reading__10': -106651, 'irradiance_sensor_id__10': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__11': datetime.datetime(2024, 4, 24, 21, 3, 29, tzinfo=datetime.timezone.utc), 'irradiance__11': -2.236, 'raw_reading__11': -107093, 'irradiance_sensor_id__11': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__12': datetime.datetime(2024, 4, 24, 21, 3, 59, tzinfo=datetime.timezone.utc), 'irradiance__12': -2.244 ... 3900 parameters truncated ... 'raw_reading__987': 10315279, 'irradiance_sensor_id__987': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__988': datetime.datetime(2024, 4, 25, 12, 34, 40, tzinfo=datetime.timezone.utc), 'irradiance__988': 195.59, 'raw_reading__988': 9368756, 'irradiance_sensor_id__988': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__989': datetime.datetime(2024, 4, 25, 12, 35, 10, tzinfo=datetime.timezone.utc), 'irradiance__989': 180.17, 'raw_reading__989': 8630145, 'irradiance_sensor_id__989': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__990': datetime.datetime(2024, 4, 25, 12, 35, 40, tzinfo=datetime.timezone.utc), 'irradiance__990': 169.965, 'raw_reading__990': 8141310, 'irradiance_sensor_id__990': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__991': datetime.datetime(2024, 4, 25, 12, 36, 10, tzinfo=datetime.timezone.utc), 'irradiance__991': 163.837, 'raw_reading__991': 7847787, 'irradiance_sensor_id__991': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__992': datetime.datetime(2024, 4, 25, 12, 36, 40, tzinfo=datetime.timezone.utc), 'irradiance__992': 161.818, 'raw_reading__992': 7751061, 'irradiance_sensor_id__992': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__993': datetime.datetime(2024, 4, 25, 12, 37, 10, tzinfo=datetime.timezone.utc), 'irradiance__993': 163.263, 'raw_reading__993': 7820316, 'irradiance_sensor_id__993': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__994': datetime.datetime(2024, 4, 25, 12, 37, 40, tzinfo=datetime.timezone.utc), 'irradiance__994': 166.957, 'raw_reading__994': 7997260, 'irradiance_sensor_id__994': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__995': datetime.datetime(2024, 4, 25, 12, 38, 10, tzinfo=datetime.timezone.utc), 'irradiance__995': 173.44, 'raw_reading__995': 8307783, 'irradiance_sensor_id__995': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__996': datetime.datetime(2024, 4, 25, 12, 38, 40, tzinfo=datetime.timezone.utc), 'irradiance__996': 182.129, 'raw_reading__996': 8723989, 'irradiance_sensor_id__996': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__997': datetime.datetime(2024, 4, 25, 12, 39, 10, tzinfo=datetime.timezone.utc), 'irradiance__997': 192.058, 'raw_reading__997': 9199563, 'irradiance_sensor_id__997': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__998': datetime.datetime(2024, 4, 25, 12, 39, 40, tzinfo=datetime.timezone.utc), 'irradiance__998': 203.141, 'raw_reading__998': 9730471, 'irradiance_sensor_id__998': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__999': datetime.datetime(2024, 4, 25, 12, 40, 10, tzinfo=datetime.timezone.utc), 'irradiance__999': 215.668, 'raw_reading__999': 10330480, 'irradiance_sensor_id__999': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93')}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-05-15 16:02:49,633 - ERROR - Error processing ../../sample_data/datasets/PeroCube-sample-data/data_20240514/data/.ipynb_checkpoints/PT-104_channel_01-checkpoint.txt: (psycopg2.errors.NotNullViolation) NULL value in column \"timestamp\" violates not-null constraint\n",
      "HINT:  Columns used for time partitioning cannot be NULL.\n",
      "\n",
      "[SQL: INSERT INTO irradiance_measurement (timestamp, raw_reading, irradiance, irradiance_sensor_id) VALUES (%(timestamp__0)s, %(raw_reading__0)s, %(irradiance__0)s, %(irradiance_sensor_id__0)s), (%(timestamp__1)s, %(raw_reading__1)s, %(irradiance__1)s, %(i ... 95309 characters truncated ... 8)s), (%(timestamp__999)s, %(raw_reading__999)s, %(irradiance__999)s, %(irradiance_sensor_id__999)s)]\n",
      "[parameters: {'timestamp__0': datetime.datetime(2024, 4, 24, 20, 57, 59, tzinfo=datetime.timezone.utc), 'irradiance__0': -2.251, 'raw_reading__0': -107844, 'irradiance_sensor_id__0': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__1': datetime.datetime(2024, 4, 24, 20, 58, 29, tzinfo=datetime.timezone.utc), 'irradiance__1': -2.238, 'raw_reading__1': -107211, 'irradiance_sensor_id__1': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__2': datetime.datetime(2024, 4, 24, 20, 58, 59, tzinfo=datetime.timezone.utc), 'irradiance__2': -2.234, 'raw_reading__2': -107030, 'irradiance_sensor_id__2': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__3': datetime.datetime(2024, 4, 24, 20, 59, 29, tzinfo=datetime.timezone.utc), 'irradiance__3': -2.242, 'raw_reading__3': -107398, 'irradiance_sensor_id__3': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__4': datetime.datetime(2024, 4, 24, 20, 59, 59, tzinfo=datetime.timezone.utc), 'irradiance__4': -2.229, 'raw_reading__4': -106782, 'irradiance_sensor_id__4': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__5': datetime.datetime(2024, 4, 24, 21, 0, 29, tzinfo=datetime.timezone.utc), 'irradiance__5': -2.226, 'raw_reading__5': -106646, 'irradiance_sensor_id__5': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__6': datetime.datetime(2024, 4, 24, 21, 0, 59, tzinfo=datetime.timezone.utc), 'irradiance__6': -2.233, 'raw_reading__6': -106953, 'irradiance_sensor_id__6': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__7': datetime.datetime(2024, 4, 24, 21, 1, 29, tzinfo=datetime.timezone.utc), 'irradiance__7': -2.233, 'raw_reading__7': -106963, 'irradiance_sensor_id__7': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__8': datetime.datetime(2024, 4, 24, 21, 1, 59, tzinfo=datetime.timezone.utc), 'irradiance__8': -2.227, 'raw_reading__8': -106668, 'irradiance_sensor_id__8': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__9': datetime.datetime(2024, 4, 24, 21, 2, 29, tzinfo=datetime.timezone.utc), 'irradiance__9': -2.227, 'raw_reading__9': -106670, 'irradiance_sensor_id__9': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__10': datetime.datetime(2024, 4, 24, 21, 2, 59, tzinfo=datetime.timezone.utc), 'irradiance__10': -2.227, 'raw_reading__10': -106651, 'irradiance_sensor_id__10': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__11': datetime.datetime(2024, 4, 24, 21, 3, 29, tzinfo=datetime.timezone.utc), 'irradiance__11': -2.236, 'raw_reading__11': -107093, 'irradiance_sensor_id__11': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__12': datetime.datetime(2024, 4, 24, 21, 3, 59, tzinfo=datetime.timezone.utc), 'irradiance__12': -2.244 ... 3900 parameters truncated ... 'raw_reading__987': 10315279, 'irradiance_sensor_id__987': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__988': datetime.datetime(2024, 4, 25, 12, 34, 40, tzinfo=datetime.timezone.utc), 'irradiance__988': 195.59, 'raw_reading__988': 9368756, 'irradiance_sensor_id__988': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__989': datetime.datetime(2024, 4, 25, 12, 35, 10, tzinfo=datetime.timezone.utc), 'irradiance__989': 180.17, 'raw_reading__989': 8630145, 'irradiance_sensor_id__989': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__990': datetime.datetime(2024, 4, 25, 12, 35, 40, tzinfo=datetime.timezone.utc), 'irradiance__990': 169.965, 'raw_reading__990': 8141310, 'irradiance_sensor_id__990': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__991': datetime.datetime(2024, 4, 25, 12, 36, 10, tzinfo=datetime.timezone.utc), 'irradiance__991': 163.837, 'raw_reading__991': 7847787, 'irradiance_sensor_id__991': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__992': datetime.datetime(2024, 4, 25, 12, 36, 40, tzinfo=datetime.timezone.utc), 'irradiance__992': 161.818, 'raw_reading__992': 7751061, 'irradiance_sensor_id__992': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__993': datetime.datetime(2024, 4, 25, 12, 37, 10, tzinfo=datetime.timezone.utc), 'irradiance__993': 163.263, 'raw_reading__993': 7820316, 'irradiance_sensor_id__993': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__994': datetime.datetime(2024, 4, 25, 12, 37, 40, tzinfo=datetime.timezone.utc), 'irradiance__994': 166.957, 'raw_reading__994': 7997260, 'irradiance_sensor_id__994': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__995': datetime.datetime(2024, 4, 25, 12, 38, 10, tzinfo=datetime.timezone.utc), 'irradiance__995': 173.44, 'raw_reading__995': 8307783, 'irradiance_sensor_id__995': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__996': datetime.datetime(2024, 4, 25, 12, 38, 40, tzinfo=datetime.timezone.utc), 'irradiance__996': 182.129, 'raw_reading__996': 8723989, 'irradiance_sensor_id__996': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__997': datetime.datetime(2024, 4, 25, 12, 39, 10, tzinfo=datetime.timezone.utc), 'irradiance__997': 192.058, 'raw_reading__997': 9199563, 'irradiance_sensor_id__997': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__998': datetime.datetime(2024, 4, 25, 12, 39, 40, tzinfo=datetime.timezone.utc), 'irradiance__998': 203.141, 'raw_reading__998': 9730471, 'irradiance_sensor_id__998': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93'), 'timestamp__999': datetime.datetime(2024, 4, 25, 12, 40, 10, tzinfo=datetime.timezone.utc), 'irradiance__999': 215.668, 'raw_reading__999': 10330480, 'irradiance_sensor_id__999': UUID('7c9b9624-a1f5-4f53-b007-7a0e80d32b93')}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n",
      "2025-05-15 16:02:50,544 - INFO - Successfully uploaded 26988 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240408/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:50,544 - INFO - Successfully uploaded 26988 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240408/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:51,416 - INFO - Successfully uploaded 26984 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240408/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:51,416 - INFO - Successfully uploaded 26984 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240408/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:52,090 - INFO - Successfully uploaded 18568 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240605/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:52,090 - INFO - Successfully uploaded 18568 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240605/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:02:52,757 - INFO - Successfully uploaded 18568 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240605/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:02:52,757 - INFO - Successfully uploaded 18568 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240605/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:02,753 - INFO - Successfully uploaded 195120 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20230920/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:02,753 - INFO - Successfully uploaded 195120 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20230920/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:09,522 - INFO - Successfully uploaded 195120 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20230920/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:09,522 - INFO - Successfully uploaded 195120 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20230920/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:10,498 - INFO - Successfully uploaded 27174 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240527/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:10,498 - INFO - Successfully uploaded 27174 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240527/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:11,436 - INFO - Successfully uploaded 27174 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240527/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:11,436 - INFO - Successfully uploaded 27174 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240527/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:30,315 - INFO - Successfully uploaded 67149 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231207/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:30,315 - INFO - Successfully uploaded 67149 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231207/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:32,708 - INFO - Successfully uploaded 67149 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231207/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:32,708 - INFO - Successfully uploaded 67149 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231207/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:33,242 - INFO - Successfully uploaded 14893 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240415/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:33,242 - INFO - Successfully uploaded 14893 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240415/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:33,793 - INFO - Successfully uploaded 14893 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240415/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:33,793 - INFO - Successfully uploaded 14893 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240415/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:34,144 - INFO - Successfully uploaded 10731 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240610/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:34,144 - INFO - Successfully uploaded 10731 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240610/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:34,567 - INFO - Successfully uploaded 10731 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240610/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:34,567 - INFO - Successfully uploaded 10731 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240610/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:56,438 - INFO - Successfully uploaded 60397 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240709/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:56,438 - INFO - Successfully uploaded 60397 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240709/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:58,575 - INFO - Successfully uploaded 60397 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240709/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:58,575 - INFO - Successfully uploaded 60397 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240709/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:59,124 - INFO - Successfully uploaded 14572 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240326/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:59,124 - INFO - Successfully uploaded 14572 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240326/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:03:59,654 - INFO - Successfully uploaded 14572 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240326/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:03:59,654 - INFO - Successfully uploaded 14572 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240326/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:00,672 - INFO - Successfully uploaded 28770 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240314/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:00,672 - INFO - Successfully uploaded 28770 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240314/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:01,601 - INFO - Successfully uploaded 26748 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240314/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:01,601 - INFO - Successfully uploaded 26748 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240314/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:04,951 - INFO - Successfully uploaded 92067 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231012/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:04,951 - INFO - Successfully uploaded 92067 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231012/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:08,014 - INFO - Successfully uploaded 92067 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231012/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:08,014 - INFO - Successfully uploaded 92067 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231012/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:13,960 - INFO - Successfully uploaded 166615 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231121/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:13,960 - INFO - Successfully uploaded 166615 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231121/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:19,695 - INFO - Successfully uploaded 166615 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231121/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:19,695 - INFO - Successfully uploaded 166615 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20231121/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:24,618 - INFO - Successfully uploaded 134178 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240108/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:24,618 - INFO - Successfully uploaded 134178 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240108/data/PT-104_channel_01.txt\n",
      "2025-05-15 16:04:29,401 - INFO - Successfully uploaded 134178 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240108/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:29,403 - INFO - Processing complete. Processed 32 files, skipped 0 files, errors in 3 files. Inserted 2107390 data points in 145.51 seconds.\n",
      "2025-05-15 16:04:29,401 - INFO - Successfully uploaded 134178 rows from ../../sample_data/datasets/PeroCube-sample-data/data_20240108/data/PT-104_channel_03.txt\n",
      "2025-05-15 16:04:29,403 - INFO - Processing complete. Processed 32 files, skipped 0 files, errors in 3 files. Inserted 2107390 data points in 145.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Review current validation configuration\n",
    "print_validation_config()\n",
    "\n",
    "# Uncomment and modify these lines to change validation settings\n",
    "# VALIDATION_CONFIG['enabled'] = True\n",
    "# VALIDATION_CONFIG['validate_ranges'] = True\n",
    "# VALIDATION_CONFIG['ranges']['irradiance']['max'] = 2000  # Adjust range if needed\n",
    "# VALIDATION_CONFIG['ranges']['temperature']['min'] = -60  # Adjust range if needed\n",
    "\n",
    "# Review current validation configuration before processing data\n",
    "print_validation_config()\n",
    "\n",
    "# Uncomment and modify these lines to change validation settings\n",
    "# VALIDATION_CONFIG['enabled'] = True\n",
    "# VALIDATION_CONFIG['validate_ranges'] = True\n",
    "# VALIDATION_CONFIG['ranges']['irradiance']['max'] = 2000  # Adjust range if needed\n",
    "# VALIDATION_CONFIG['ranges']['temperature']['min'] = -60  # Adjust range if needed\n",
    "\n",
    "# Step 2: Process and upload irradiance data\n",
    "print(\"\\n3. Processing irradiance data files...\")\n",
    "irr_stats = process_irradiance_files(ROOT_DIRECTORY, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9de6b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:04:29,427 - INFO - Found 43 temperature data files to process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Processing temperature data files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ff7526d1ae4deebaa00f3c38bbee51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Temperature Files:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:04:29,436 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,436 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,437 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,437 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,437 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,436 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,437 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,437 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,437 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,438 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,438 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,438 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: CE000008AA0F6528. Skipping file.\n",
      "2025-05-15 16:04:29,440 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,440 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,438 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,438 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,438 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,439 - WARNING - No registered sensor found for identifier: CE000008AA0F6528. Skipping file.\n",
      "2025-05-15 16:04:29,440 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,440 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,441 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,441 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,441 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,443 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,444 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,444 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,445 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,446 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,446 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,446 - WARNING - No registered sensor found for identifier: CE000008AA0F6528. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: CE000008AA0F6528. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,448 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,448 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,448 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,441 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,441 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,441 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,443 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,444 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,444 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,445 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,446 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,446 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,446 - WARNING - No registered sensor found for identifier: CE000008AA0F6528. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: CE000008AA0F6528. Skipping file.\n",
      "2025-05-15 16:04:29,447 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,448 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,448 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,448 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: 3F00000A108FDE28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,449 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,451 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,451 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n",
      "2025-05-15 16:04:29,450 - WARNING - No registered sensor found for identifier: B700000D569E0C28. Skipping file.\n",
      "2025-05-15 16:04:29,451 - WARNING - No registered sensor found for identifier: 37F6F9511A64FF28. Skipping file.\n",
      "2025-05-15 16:04:29,451 - WARNING - No registered sensor found for identifier: DB00000B2A5F9F28. Skipping file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:04:29,452 - INFO - Processing complete. Processed 0 files, skipped 43 files, errors in 0 files. Inserted 0 data points in 0.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Process and upload temperature data\n",
    "print(\"\\n4. Processing temperature data files...\")\n",
    "temp_stats = process_temperature_files(ROOT_DIRECTORY, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d1002",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e459c72-da19-4b28-bb87-1a7aac77d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== UPLOAD SUMMARY =====\n",
      "\n",
      "SENSOR REGISTRATION:\n",
      "- Irradiance Sensors: 0 found, 0 newly registered, 2 already existing\n",
      "- Temperature Sensors: 0 found, 0 newly registered, 5 already existing\n",
      "\n",
      "DATA PROCESSING:\n",
      "Irradiance Data:\n",
      "- Files processed: 32\n",
      "- Files skipped: 0\n",
      "- Files with errors: 3\n",
      "- Rows inserted: 2107390\n",
      "- Processing time: 145.51 seconds\n",
      "\n",
      "Temperature Data:\n",
      "- Files processed: 0\n",
      "- Files skipped: 43\n",
      "- Files with errors: 0\n",
      "- Rows inserted: 0\n",
      "- Processing time: 0.03 seconds\n",
      "\n",
      "DATABASE VERIFICATION:\n",
      "- Total irradiance measurements: 2152390\n",
      "- Total temperature measurements: 0\n",
      "- Total irradiance sensors: 2\n",
      "- Total temperature sensors: 5\n",
      "- Total irradiance measurements: 2152390\n",
      "- Total temperature measurements: 0\n",
      "- Total irradiance sensors: 2\n",
      "- Total temperature sensors: 5\n"
     ]
    }
   ],
   "source": [
    "# Display processing statistics\n",
    "print(\"\\n===== UPLOAD SUMMARY =====\\n\")\n",
    "\n",
    "# Sensor registration summary\n",
    "print(\"SENSOR REGISTRATION:\")\n",
    "print(f\"- Irradiance Sensors: {irr_sensor_stats.get('sensors_found', 0)} found, \"\n",
    "      f\"{irr_sensor_stats.get('sensors_registered', 0)} newly registered, \"\n",
    "      f\"{irr_sensor_stats.get('sensors_existing', 0)} already existing\")\n",
    "\n",
    "print(f\"- Temperature Sensors: {temp_sensor_stats.get('sensors_found', 0)} found, \"\n",
    "      f\"{temp_sensor_stats.get('sensors_registered', 0)} newly registered, \"\n",
    "      f\"{temp_sensor_stats.get('sensors_existing', 0)} already existing\")\n",
    "\n",
    "# Data processing summary\n",
    "print(\"\\nDATA PROCESSING:\")\n",
    "print(\"Irradiance Data:\")\n",
    "print(f\"- Files processed: {irr_stats.get('files_processed', 0)}\")\n",
    "print(f\"- Files skipped: {irr_stats.get('files_skipped', 0)}\")\n",
    "print(f\"- Files with errors: {irr_stats.get('files_error', 0)}\")\n",
    "print(f\"- Rows inserted: {irr_stats.get('rows_inserted', 0)}\")\n",
    "if 'duration_seconds' in irr_stats:\n",
    "    print(f\"- Processing time: {irr_stats['duration_seconds']:.2f} seconds\")\n",
    "\n",
    "print(\"\\nTemperature Data:\")\n",
    "print(f\"- Files processed: {temp_stats.get('files_processed', 0)}\")\n",
    "print(f\"- Files skipped: {temp_stats.get('files_skipped', 0)}\")\n",
    "print(f\"- Files with errors: {temp_stats.get('files_error', 0)}\")\n",
    "print(f\"- Rows inserted: {temp_stats.get('rows_inserted', 0)}\")\n",
    "if 'duration_seconds' in temp_stats:\n",
    "    print(f\"- Processing time: {temp_stats['duration_seconds']:.2f} seconds\")\n",
    "\n",
    "# Verify database counts\n",
    "try:\n",
    "    print(\"\\nDATABASE VERIFICATION:\")\n",
    "    with engine.connect() as conn:\n",
    "        # Get irradiance data counts\n",
    "        result = conn.execute(text(f\"SELECT COUNT(*) FROM {IRRADIANCE_MEASUREMENT_TABLE}\"))\n",
    "        irradiance_count = result.scalar()\n",
    "        print(f\"- Total irradiance measurements: {irradiance_count}\")\n",
    "        \n",
    "        # Get temperature data counts\n",
    "        result = conn.execute(text(f\"SELECT COUNT(*) FROM {TEMPERATURE_MEASUREMENT_TABLE}\"))\n",
    "        temperature_count = result.scalar()\n",
    "        print(f\"- Total temperature measurements: {temperature_count}\")\n",
    "        \n",
    "        # Get sensor counts\n",
    "        result = conn.execute(text(f\"SELECT COUNT(*) FROM {IRRADIANCE_SENSOR_TABLE}\"))\n",
    "        irradiance_sensor_count = result.scalar()\n",
    "        print(f\"- Total irradiance sensors: {irradiance_sensor_count}\")\n",
    "        \n",
    "        result = conn.execute(text(f\"SELECT COUNT(*) FROM {TEMPERATURE_SENSOR_TABLE}\"))\n",
    "        temperature_sensor_count = result.scalar()\n",
    "        print(f\"- Total temperature sensors: {temperature_sensor_count}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not query database: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
