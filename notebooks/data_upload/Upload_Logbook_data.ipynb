{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7e94ca",
   "metadata": {},
   "source": [
    "# Perocube Logbook Data Upload Notebook\n",
    "\n",
    "This notebook processes and uploads logbook data from the Perocube Excel file to the TimescaleDB database.\n",
    "\n",
    "## Purpose\n",
    "- Read logbook data from 'PeroCube_logbook_example.xlsx'\n",
    "- Parse and validate the data\n",
    "- Upload the data to the TimescaleDB database\n",
    "- Avoid duplicate data entries\n",
    "\n",
    "## Prerequisites\n",
    "- Running TimescaleDB instance (configured in docker-compose.yml)\n",
    "- Access to the Perocube logbook Excel file\n",
    "- Environment variables configured in .env file (for database connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e0476",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import required libraries and install any missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data processing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Database libraries\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af362b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install psycopg2-binary sqlalchemy pandas tqdm pathlib python-dotenv openpyxl\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41d919",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Load configuration from environment variables and set up constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for the .env file two directories up from the notebook location\n",
    "dotenv_path = Path(\"../../.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Database configuration from environment variables with fallbacks\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),\n",
    "    'port': int(os.getenv('DB_PORT', 5432)),\n",
    "    'database': os.getenv('DB_NAME', 'perocube'),\n",
    "    'user': os.getenv('DB_USER', 'postgres'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'postgres')\n",
    "}\n",
    "\n",
    "# Print database connection info (excluding password)\n",
    "print(f\"Database connection: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']} as {DB_CONFIG['user']}\")\n",
    "\n",
    "# Data directory and file configuration\n",
    "ROOT_DIRECTORY = os.getenv('DEFAULT_DATA_DIR', \"../../sample_data/datasets/PeroCube-sample-data\")\n",
    "LOGBOOK_FILE = \"PeroCube_logbook_example.xlsx\"\n",
    "LOGBOOK_SHEET = \"Perocube history\"\n",
    "\n",
    "# Batch size for database operations\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd22ffb",
   "metadata": {},
   "source": [
    "## 3. Read and Process Logbook Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb4796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full path to the logbook file\n",
    "logbook_path = Path(ROOT_DIRECTORY) / LOGBOOK_FILE\n",
    "\n",
    "# Read the Excel sheet, skip first row and use second row as header\n",
    "try:\n",
    "    df = pd.read_excel(logbook_path, sheet_name=LOGBOOK_SHEET, header=1)\n",
    "    print(f\"Successfully read {len(df)} rows from {LOGBOOK_FILE}\")\n",
    "    \n",
    "    # Display the first few rows and data info\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(\"\\nFirst few rows of the data:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\nDataset information:\")\n",
    "    display(df.info())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading Excel file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze current dataframe state\n",
    "print(\"Checking for unnamed columns:\")\n",
    "unnamed_cols = [col for col in df.columns if 'Unnamed' in str(col)]\n",
    "print(f\"Unnamed columns found: {unnamed_cols}\")\n",
    "\n",
    "print(\"\\nCurrent data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTotal rows with all missing values:\")\n",
    "print(df.isna().all(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe\n",
    "\n",
    "# 1. Remove unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('Unnamed')]\n",
    "\n",
    "# 2. Drop rows where all values are missing\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# Print cleaning results\n",
    "print(\"Dataframe shape after cleaning:\")\n",
    "print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "# Display updated column list\n",
    "print(\"\\nUpdated column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display updated missing values count\n",
    "print(\"\\nMissing values per column after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display first few rows of cleaned data\n",
    "print(\"\\nFirst few rows of cleaned data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e47291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove completely empty Comment 2 column\n",
    "df = df.drop('Comment 2', axis=1)\n",
    "\n",
    "# Print updated dataframe info\n",
    "print(\"Dataframe shape after removing Comment 2:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "# Display updated column list\n",
    "print(\"\\nUpdated column names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display first few rows of cleaned data\n",
    "print(\"\\nFirst few rows of cleaned data:\")\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
