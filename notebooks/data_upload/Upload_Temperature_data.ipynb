{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315f7792",
   "metadata": {},
   "source": [
    "\n",
    "This notebook processes and uploads temperature measurement data from text files to the TimescaleDB database.\n",
    "\n",
    "## Purpose\n",
    "- Scan directories for temperature data files (m7004_ID_{identifier}.txt files)\n",
    "- Parse the data into structured format\n",
    "- Upload the data to the TimescaleDB database\n",
    "- Avoid duplicate data entries\n",
    "\n",
    "## Prerequisites\n",
    "- Running TimescaleDB instance (configured in docker-compose.yml)\n",
    "- Access to directory containing temperature data files\n",
    "- Environment variables configured in .env file (for database connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c4dd5",
   "metadata": {},
   "source": [
    "\n",
    "Import required libraries and install any missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d37f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Database libraries\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d46c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.11/site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.11/site-packages (2.0.22)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: pathlib in /opt/conda/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary sqlalchemy pandas tqdm pathlib python-dotenv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc395f41",
   "metadata": {},
   "source": [
    "\n",
    "Load configuration from environment variables and set up constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92419fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection: timescaledb:5432/perocube as postgres\n"
     ]
    }
   ],
   "source": [
    "# Look for the .env file two directories up from the notebook location\n",
    "dotenv_path = Path(\"../../.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Database configuration from container environment variables with fallbacks\n",
    "DB_CONFIG = {\n",
    "    'host': os.getenv('POSTGRES_HOST', 'timescaledb'),  # Use container service name\n",
    "    'port': int(os.getenv('POSTGRES_PORT', 5432)),\n",
    "    'database': os.getenv('POSTGRES_DB', 'perocube'),\n",
    "    'user': os.getenv('POSTGRES_USER', 'postgres'),\n",
    "    'password': os.getenv('POSTGRES_PASSWORD', 'postgres')\n",
    "}\n",
    "\n",
    "# Print database connection info (excluding password)\n",
    "print(f\"Database connection: {DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']} as {DB_CONFIG['user']}\")\n",
    "\n",
    "# Data directory configuration - using relative path from notebook location\n",
    "ROOT_DIRECTORY = str(Path(\"../../sample_data/datasets/PeroCube-sample-data\").resolve())\n",
    "\n",
    "# File matching pattern for temperature data\n",
    "TEMPERATURE_FILE_PATTERN = r\"m7004_ID_([A-F0-9]+)\\.txt$\"\n",
    "\n",
    "# Batch size for database operations\n",
    "BATCH_SIZE = 5000\n",
    "\n",
    "# UUID namespace for temperature sensors (same as irradiance for consistency)\n",
    "SENSOR_UUID_NAMESPACE = uuid.UUID('12345678-1234-5678-1234-567812345678')\n",
    "\n",
    "# Data validation configuration\n",
    "VALIDATION_CONFIG = {\n",
    "    'enabled': True,  # Master switch for validation\n",
    "    'remove_nan': True,  # Always remove NaN values from timestamp column\n",
    "}\n",
    "\n",
    "def print_validation_config():\n",
    "    \"\"\"Print current validation configuration for user awareness\"\"\"\n",
    "    print(\"\\nData Validation Configuration:\")\n",
    "    print(f\"- Validation enabled: {VALIDATION_CONFIG['enabled']}\")\n",
    "    print(f\"- Remove NaN values from timestamp: {VALIDATION_CONFIG['remove_nan']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8219f1",
   "metadata": {},
   "source": [
    "\n",
    "Define helper functions for database connection, data validation, and sensor management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db85be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_connection(config=DB_CONFIG):\n",
    "    \"\"\"\n",
    "    Create a SQLAlchemy database engine from configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: Dictionary containing database connection parameters\n",
    "        \n",
    "    Returns:\n",
    "        SQLAlchemy engine instance\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection_string = f\"postgresql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\"\n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Test the connection\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT 1\"))\n",
    "            logging.info(f\"Database connection successful: {config['host']}:{config['port']}/{config['database']}\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Database connection failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def generate_sensor_id(sensor_identifier):\n",
    "    \"\"\"\n",
    "    Generate a deterministic UUID for a temperature sensor based on its identifier.\n",
    "    \n",
    "    Args:\n",
    "        sensor_identifier (str): Complete sensor identifier (e.g., 'm7004_ID_37F6F9511A64FF28')\n",
    "        \n",
    "    Returns:\n",
    "        UUID: Deterministic UUID5 for the sensor\n",
    "    \"\"\"\n",
    "    return uuid.uuid5(SENSOR_UUID_NAMESPACE, sensor_identifier)\n",
    "\n",
    "def get_or_create_sensor(engine, sensor_identifier):\n",
    "    \"\"\"\n",
    "    Get existing sensor or create a new one if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        engine: SQLAlchemy engine instance\n",
    "        sensor_identifier (str): Complete sensor identifier (e.g., 'm7004_ID_37F6F9511A64FF28')\n",
    "        \n",
    "    Returns:\n",
    "        UUID: sensor_id of the existing or newly created sensor\n",
    "    \"\"\"\n",
    "    sensor_id = generate_sensor_id(sensor_identifier)\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            # Check if sensor exists\n",
    "            result = conn.execute(\n",
    "                text(\"\"\"\n",
    "                SELECT temperature_sensor_id \n",
    "                FROM temperature_sensor \n",
    "                WHERE sensor_identifier = :identifier\n",
    "                \"\"\"),\n",
    "                {\"identifier\": sensor_identifier}\n",
    "            )\n",
    "            \n",
    "            if not result.fetchone():\n",
    "                # Create new sensor if it doesn't exist\n",
    "                conn.execute(\n",
    "                    text(\"\"\"\n",
    "                    INSERT INTO temperature_sensor \n",
    "                    (temperature_sensor_id, sensor_identifier, date_installed) \n",
    "                    VALUES (:id, :identifier, NULL)\n",
    "                    \"\"\"),\n",
    "                    {\n",
    "                        \"id\": sensor_id,\n",
    "                        \"identifier\": sensor_identifier\n",
    "                    }\n",
    "                )\n",
    "                conn.commit()\n",
    "                logging.info(f\"Created new sensor: {sensor_identifier}\")\n",
    "            else:\n",
    "                logging.info(f\"Found existing sensor: {sensor_identifier}\")\n",
    "                \n",
    "        return sensor_id\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in get_or_create_sensor: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def validate_temperature_data(df):\n",
    "    \"\"\"\n",
    "    Validate temperature measurement data according to configuration.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing temperature measurements\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned and validated DataFrame, along with validation statistics\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df, {'initial_count': 0, 'final_count': 0, 'removed': {}}\n",
    "    \n",
    "    stats = {\n",
    "        'initial_count': len(df),\n",
    "        'final_count': None,\n",
    "        'removed': {\n",
    "            'nan_values': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Always ensure timestamp is in UTC\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "    \n",
    "    # Remove NaN values from timestamp column as required by TimescaleDB\n",
    "    if VALIDATION_CONFIG['remove_nan']:\n",
    "        nan_count = df['timestamp'].isna().sum()\n",
    "        df = df.dropna(subset=['timestamp'])\n",
    "        stats['removed']['nan_values'] = nan_count\n",
    "    \n",
    "    stats['final_count'] = len(df)\n",
    "    \n",
    "    # Log validation results\n",
    "    logging.info(\"Validation statistics:\")\n",
    "    logging.info(f\"Initial records: {stats['initial_count']}\")\n",
    "    if VALIDATION_CONFIG['remove_nan']:\n",
    "        logging.info(f\"Removed timestamp NaN values: {stats['removed']['nan_values']}\")\n",
    "    logging.info(f\"Final records: {stats['final_count']}\")\n",
    "    \n",
    "    return df, stats\n",
    "\n",
    "def check_existing_data(engine, sensor_identifier, timestamps):\n",
    "    \"\"\"\n",
    "    Check if data already exists in the database for given parameters.\n",
    "    \n",
    "    Args:\n",
    "        engine: SQLAlchemy engine\n",
    "        sensor_identifier: Temperature sensor identifier\n",
    "        timestamps: List of timestamps to check\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if data exists\n",
    "    \"\"\"\n",
    "    if not timestamps:\n",
    "        return False\n",
    "        \n",
    "    # For efficiency, just check the min and max timestamps\n",
    "    min_timestamp = min(timestamps)\n",
    "    max_timestamp = max(timestamps)\n",
    "    \n",
    "    sensor_id = generate_sensor_id(sensor_identifier)\n",
    "    \n",
    "    # Build a query to check for existing data\n",
    "    query = text(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM temperature_measurement\n",
    "        WHERE timestamp BETWEEN :min_timestamp AND :max_timestamp\n",
    "          AND temperature_sensor_id = :sensor_id\n",
    "    \"\"\")\n",
    "    \n",
    "    # Execute the query\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {\n",
    "            \"min_timestamp\": min_timestamp,\n",
    "            \"max_timestamp\": max_timestamp,\n",
    "            \"sensor_id\": sensor_id\n",
    "        })\n",
    "        count = result.scalar()\n",
    "        \n",
    "    # If count > 0, some data exists\n",
    "    return count > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda00a17",
   "metadata": {},
   "source": [
    "\n",
    "Main function to process and upload temperature data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff479f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_temperature_files(root_dir, engine, pattern=TEMPERATURE_FILE_PATTERN, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Process temperature data files and upload measurements to the database.\n",
    "    \n",
    "    Args:\n",
    "        root_dir: Root directory to search for files\n",
    "        engine: SQLAlchemy engine instance\n",
    "        pattern: Regex pattern to match files\n",
    "        batch_size: Number of records to process in one batch\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with processing statistics\n",
    "    \"\"\"\n",
    "    # Statistics to track progress\n",
    "    stats = {\n",
    "        'files_processed': 0,\n",
    "        'files_skipped': 0,\n",
    "        'files_error': 0,\n",
    "        'rows_inserted': 0,\n",
    "        'start_time': datetime.now(timezone.utc),\n",
    "        'total_files': 0\n",
    "    }\n",
    "    \n",
    "    # Convert to Path object\n",
    "    root_path = Path(root_dir)\n",
    "    if not root_path.exists():\n",
    "        logging.error(f\"Root directory does not exist: {root_dir}\")\n",
    "        return stats\n",
    "    \n",
    "    # Compile regex pattern\n",
    "    pattern_compiled = re.compile(pattern)\n",
    "    \n",
    "    # Find all matching files\n",
    "    matching_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        path_parts = Path(dirpath).parts\n",
    "        if any(part.startswith(\"data\") for part in path_parts):\n",
    "            for filename in filenames:\n",
    "                filepath = Path(dirpath) / filename\n",
    "                match = pattern_compiled.search(filename)\n",
    "                if match:\n",
    "                    identifier = match.group(1)\n",
    "                    sensor_identifier = f\"m7004_ID_{identifier}\"\n",
    "                    matching_files.append((filepath, sensor_identifier))\n",
    "    \n",
    "    stats['total_files'] = len(matching_files)\n",
    "    logging.info(f\"Found {len(matching_files)} temperature data files to process\")\n",
    "    \n",
    "    # Process each file\n",
    "    with tqdm(total=len(matching_files), desc=\"Processing Files\") as pbar:\n",
    "        for filepath, sensor_identifier in matching_files:\n",
    "            try:\n",
    "                logging.info(f\"Processing file: {filepath}\")\n",
    "                logging.info(f\"Sensor: {sensor_identifier}\")\n",
    "                \n",
    "                # Read the data file\n",
    "                df = pd.read_csv(filepath, sep='\\t',\n",
    "                               names=['timestamp', 'temperature'])\n",
    "                \n",
    "                if df.empty:\n",
    "                    logging.warning(f\"Empty file: {filepath}\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Validate data\n",
    "                df, validation_stats = validate_temperature_data(df)\n",
    "                if df.empty:\n",
    "                    logging.warning(f\"No valid data after validation: {filepath}\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Check for existing data\n",
    "                if check_existing_data(engine, sensor_identifier, df['timestamp'].tolist()):\n",
    "                    logging.info(f\"Data already exists for {filepath}. Skipping file.\")\n",
    "                    stats['files_skipped'] += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Get or create sensor\n",
    "                sensor_id = get_or_create_sensor(engine, sensor_identifier)\n",
    "                \n",
    "                # Add sensor_id to DataFrame\n",
    "                df['temperature_sensor_id'] = sensor_id\n",
    "                \n",
    "                # Upload data in batches\n",
    "                total_rows = len(df)\n",
    "                for i in range(0, total_rows, batch_size):\n",
    "                    batch_df = df.iloc[i:i+batch_size]\n",
    "                    batch_df.to_sql('temperature_measurement', engine, \n",
    "                                  if_exists='append', index=False)\n",
    "                \n",
    "                stats['rows_inserted'] += total_rows\n",
    "                stats['files_processed'] += 1\n",
    "                logging.info(f\"Successfully uploaded {total_rows} rows from {filepath}\")\n",
    "                \n",
    "                # Clean up\n",
    "                del df\n",
    "                pbar.update(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {filepath}: {str(e)}\")\n",
    "                stats['files_error'] += 1\n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Calculate duration\n",
    "    stats['end_time'] = datetime.now(timezone.utc)\n",
    "    stats['duration_seconds'] = (stats['end_time'] - stats['start_time']).total_seconds()\n",
    "    \n",
    "    logging.info(f\"Processing complete. \"\n",
    "                 f\"Processed {stats['files_processed']} files, \"\n",
    "                 f\"skipped {stats['files_skipped']} files, \"\n",
    "                 f\"errors in {stats['files_error']} files. \"\n",
    "                 f\"Inserted {stats['rows_inserted']} data points \"\n",
    "                 f\"in {stats['duration_seconds']:.2f} seconds.\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef9d19",
   "metadata": {},
   "source": [
    "## 5. Execute the Data Upload Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4778782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 09:09:22,097 - INFO - Database connection successful: timescaledb:5432/perocube\n",
      "2025-05-22 09:09:22,099 - INFO - Database connection established successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    engine = create_db_connection()\n",
    "    logging.info(\"Database connection established successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to connect to database: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6db20519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation Configuration:\n",
      "- Validation enabled: True\n",
      "- Remove NaN values from timestamp: True\n"
     ]
    }
   ],
   "source": [
    "print_validation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf8c4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 09:09:32,321 - INFO - Found 43 temperature data files to process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting temperature data processing from directory: /home/jovyan/sample_data/datasets/PeroCube-sample-data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df8bd0fb370470ab913fea295599076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 09:09:32,331 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240319/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:32,332 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:32,346 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:32,347 - INFO - Initial records: 10716\n",
      "2025-05-22 09:09:32,348 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:32,348 - INFO - Final records: 10716\n",
      "2025-05-22 09:09:32,419 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240319/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:32,420 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240319/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:32,420 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:32,432 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:32,432 - INFO - Initial records: 10716\n",
      "2025-05-22 09:09:32,433 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:32,433 - INFO - Final records: 10716\n",
      "2025-05-22 09:09:32,442 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240319/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:32,443 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240319/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:32,444 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:32,454 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:32,455 - INFO - Initial records: 10716\n",
      "2025-05-22 09:09:32,455 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:32,456 - INFO - Final records: 10716\n",
      "2025-05-22 09:09:32,464 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240319/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:32,464 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240222/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:32,465 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:32,479 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:32,480 - INFO - Initial records: 7552\n",
      "2025-05-22 09:09:32,480 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:32,481 - INFO - Final records: 7552\n",
      "2025-05-22 09:09:32,496 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240222/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:32,496 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240220/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:32,497 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:32,584 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:32,585 - INFO - Initial records: 179262\n",
      "2025-05-22 09:09:32,585 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:32,585 - INFO - Final records: 179262\n",
      "2025-05-22 09:09:32,777 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240220/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:32,778 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240220/data/m7004_ID_37F6F9511A64FF28.txt\n",
      "2025-05-22 09:09:32,778 - INFO - Sensor: m7004_ID_37F6F9511A64FF28\n",
      "2025-05-22 09:09:32,867 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:32,868 - INFO - Initial records: 179262\n",
      "2025-05-22 09:09:32,868 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:32,870 - INFO - Final records: 179262\n",
      "2025-05-22 09:09:33,053 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240220/data/m7004_ID_37F6F9511A64FF28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,054 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240220/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:33,056 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:33,147 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,148 - INFO - Initial records: 179262\n",
      "2025-05-22 09:09:33,149 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,149 - INFO - Final records: 179262\n",
      "2025-05-22 09:09:33,327 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240220/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,327 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240514/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:33,328 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:33,359 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,360 - INFO - Initial records: 61382\n",
      "2025-05-22 09:09:33,360 - INFO - Removed timestamp NaN values: 1\n",
      "2025-05-22 09:09:33,360 - INFO - Final records: 61381\n",
      "2025-05-22 09:09:33,406 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240514/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,407 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240514/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:33,408 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:33,439 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,440 - INFO - Initial records: 61382\n",
      "2025-05-22 09:09:33,440 - INFO - Removed timestamp NaN values: 1\n",
      "2025-05-22 09:09:33,440 - INFO - Final records: 61381\n",
      "2025-05-22 09:09:33,517 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240514/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,518 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240408/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:33,519 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:33,534 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,535 - INFO - Initial records: 26992\n",
      "2025-05-22 09:09:33,536 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,536 - INFO - Final records: 26992\n",
      "2025-05-22 09:09:33,562 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240408/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,563 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240408/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:33,563 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:33,579 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,580 - INFO - Initial records: 26992\n",
      "2025-05-22 09:09:33,581 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,581 - INFO - Final records: 26992\n",
      "2025-05-22 09:09:33,599 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240408/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,600 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240605/data/m7004_ID_CE000008AA0F6528.txt\n",
      "2025-05-22 09:09:33,601 - INFO - Sensor: m7004_ID_CE000008AA0F6528\n",
      "2025-05-22 09:09:33,610 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,611 - INFO - Initial records: 12609\n",
      "2025-05-22 09:09:33,611 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,611 - INFO - Final records: 12609\n",
      "2025-05-22 09:09:33,664 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240605/data/m7004_ID_CE000008AA0F6528.txt. Skipping file.\n",
      "2025-05-22 09:09:33,666 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240605/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:33,666 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:33,683 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,684 - INFO - Initial records: 19276\n",
      "2025-05-22 09:09:33,684 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,684 - INFO - Final records: 19276\n",
      "2025-05-22 09:09:33,705 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240605/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,706 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240605/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:33,707 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:33,723 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,723 - INFO - Initial records: 19276\n",
      "2025-05-22 09:09:33,724 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,724 - INFO - Final records: 19276\n",
      "2025-05-22 09:09:33,738 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240605/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:33,739 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20230920/data/m7004_ID_37F6F9511A64FF28.txt\n",
      "2025-05-22 09:09:33,740 - INFO - Sensor: m7004_ID_37F6F9511A64FF28\n",
      "2025-05-22 09:09:33,835 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:33,836 - INFO - Initial records: 190775\n",
      "2025-05-22 09:09:33,836 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:33,837 - INFO - Final records: 190775\n",
      "2025-05-22 09:09:34,037 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20230920/data/m7004_ID_37F6F9511A64FF28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,038 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20230920/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:34,038 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:34,135 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,136 - INFO - Initial records: 190760\n",
      "2025-05-22 09:09:34,136 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,137 - INFO - Final records: 190760\n",
      "2025-05-22 09:09:34,322 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20230920/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,323 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240527/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:34,324 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:34,344 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,345 - INFO - Initial records: 27924\n",
      "2025-05-22 09:09:34,346 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,347 - INFO - Final records: 27924\n",
      "2025-05-22 09:09:34,367 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240527/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,368 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240527/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:34,368 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:34,383 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,384 - INFO - Initial records: 27924\n",
      "2025-05-22 09:09:34,385 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,385 - INFO - Final records: 27924\n",
      "2025-05-22 09:09:34,445 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240527/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,445 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231207/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:34,447 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:34,480 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,481 - INFO - Initial records: 67138\n",
      "2025-05-22 09:09:34,482 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,482 - INFO - Final records: 67138\n",
      "2025-05-22 09:09:34,538 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231207/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,539 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231207/data/m7004_ID_37F6F9511A64FF28.txt\n",
      "2025-05-22 09:09:34,540 - INFO - Sensor: m7004_ID_37F6F9511A64FF28\n",
      "2025-05-22 09:09:34,573 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,573 - INFO - Initial records: 67155\n",
      "2025-05-22 09:09:34,574 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,574 - INFO - Final records: 67155\n",
      "2025-05-22 09:09:34,655 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231207/data/m7004_ID_37F6F9511A64FF28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,656 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231207/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:34,656 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:34,692 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,693 - INFO - Initial records: 67155\n",
      "2025-05-22 09:09:34,694 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,695 - INFO - Final records: 67155\n",
      "2025-05-22 09:09:34,776 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231207/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,776 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240415/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:34,777 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:34,789 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,789 - INFO - Initial records: 14894\n",
      "2025-05-22 09:09:34,790 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,791 - INFO - Final records: 14894\n",
      "2025-05-22 09:09:34,801 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240415/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,801 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240415/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:34,802 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:34,813 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,813 - INFO - Initial records: 14894\n",
      "2025-05-22 09:09:34,813 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,814 - INFO - Final records: 14894\n",
      "2025-05-22 09:09:34,824 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240415/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,825 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240610/data/m7004_ID_CE000008AA0F6528.txt\n",
      "2025-05-22 09:09:34,825 - INFO - Sensor: m7004_ID_CE000008AA0F6528\n",
      "2025-05-22 09:09:34,834 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,835 - INFO - Initial records: 11123\n",
      "2025-05-22 09:09:34,836 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,836 - INFO - Final records: 11123\n",
      "2025-05-22 09:09:34,851 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240610/data/m7004_ID_CE000008AA0F6528.txt. Skipping file.\n",
      "2025-05-22 09:09:34,852 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240610/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:34,852 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:34,861 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,862 - INFO - Initial records: 11123\n",
      "2025-05-22 09:09:34,863 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,863 - INFO - Final records: 11123\n",
      "2025-05-22 09:09:34,875 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240610/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,875 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240610/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:34,876 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:34,885 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,886 - INFO - Initial records: 11123\n",
      "2025-05-22 09:09:34,887 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,887 - INFO - Final records: 11123\n",
      "2025-05-22 09:09:34,935 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240610/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:34,936 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240709/data/m7004_ID_CE000008AA0F6528.txt\n",
      "2025-05-22 09:09:34,938 - INFO - Sensor: m7004_ID_CE000008AA0F6528\n",
      "2025-05-22 09:09:34,973 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:34,973 - INFO - Initial records: 62675\n",
      "2025-05-22 09:09:34,974 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:34,974 - INFO - Final records: 62675\n",
      "2025-05-22 09:09:35,018 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240709/data/m7004_ID_CE000008AA0F6528.txt. Skipping file.\n",
      "2025-05-22 09:09:35,019 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240709/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:35,019 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:35,051 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,052 - INFO - Initial records: 62675\n",
      "2025-05-22 09:09:35,052 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,053 - INFO - Final records: 62675\n",
      "2025-05-22 09:09:35,134 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240709/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,135 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240709/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:35,135 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:35,168 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,168 - INFO - Initial records: 62675\n",
      "2025-05-22 09:09:35,169 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,170 - INFO - Final records: 62675\n",
      "2025-05-22 09:09:35,243 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240709/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,244 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240326/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:35,245 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:35,256 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,256 - INFO - Initial records: 14575\n",
      "2025-05-22 09:09:35,257 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,258 - INFO - Final records: 14575\n",
      "2025-05-22 09:09:35,273 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240326/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,273 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240326/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:35,274 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:35,285 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,286 - INFO - Initial records: 14575\n",
      "2025-05-22 09:09:35,287 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,288 - INFO - Final records: 14575\n",
      "2025-05-22 09:09:35,298 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240326/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,299 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240326/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:35,299 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:35,310 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,310 - INFO - Initial records: 14575\n",
      "2025-05-22 09:09:35,310 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,311 - INFO - Final records: 14575\n",
      "2025-05-22 09:09:35,323 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240326/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,323 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240314/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:35,324 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:35,341 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,342 - INFO - Initial records: 28806\n",
      "2025-05-22 09:09:35,342 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,343 - INFO - Final records: 28806\n",
      "2025-05-22 09:09:35,365 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240314/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,366 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240314/data/m7004_ID_3F00000A108FDE28.txt\n",
      "2025-05-22 09:09:35,366 - INFO - Sensor: m7004_ID_3F00000A108FDE28\n",
      "2025-05-22 09:09:35,383 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,383 - INFO - Initial records: 28806\n",
      "2025-05-22 09:09:35,383 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,384 - INFO - Final records: 28806\n",
      "2025-05-22 09:09:35,436 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240314/data/m7004_ID_3F00000A108FDE28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,437 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240314/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:35,438 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:35,456 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,457 - INFO - Initial records: 28806\n",
      "2025-05-22 09:09:35,458 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,459 - INFO - Final records: 28806\n",
      "2025-05-22 09:09:35,476 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240314/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,476 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231012/data/m7004_ID_37F6F9511A64FF28.txt\n",
      "2025-05-22 09:09:35,478 - INFO - Sensor: m7004_ID_37F6F9511A64FF28\n",
      "2025-05-22 09:09:35,525 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,526 - INFO - Initial records: 92076\n",
      "2025-05-22 09:09:35,527 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,527 - INFO - Final records: 92076\n",
      "2025-05-22 09:09:35,624 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231012/data/m7004_ID_37F6F9511A64FF28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,625 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231012/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:35,625 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:35,667 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,668 - INFO - Initial records: 92076\n",
      "2025-05-22 09:09:35,669 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,669 - INFO - Final records: 92076\n",
      "2025-05-22 09:09:35,758 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231012/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:35,759 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231121/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:35,759 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:35,837 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:35,838 - INFO - Initial records: 166628\n",
      "2025-05-22 09:09:35,840 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:35,840 - INFO - Final records: 166628\n",
      "2025-05-22 09:09:36,021 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231121/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:36,022 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231121/data/m7004_ID_37F6F9511A64FF28.txt\n",
      "2025-05-22 09:09:36,023 - INFO - Sensor: m7004_ID_37F6F9511A64FF28\n",
      "2025-05-22 09:09:36,100 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:36,101 - INFO - Initial records: 166628\n",
      "2025-05-22 09:09:36,101 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:36,102 - INFO - Final records: 166628\n",
      "2025-05-22 09:09:36,225 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231121/data/m7004_ID_37F6F9511A64FF28.txt. Skipping file.\n",
      "2025-05-22 09:09:36,225 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231121/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:36,226 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:36,302 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:36,302 - INFO - Initial records: 166628\n",
      "2025-05-22 09:09:36,303 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:36,303 - INFO - Final records: 166628\n",
      "2025-05-22 09:09:36,463 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20231121/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:36,464 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240108/data/m7004_ID_B700000D569E0C28.txt\n",
      "2025-05-22 09:09:36,465 - INFO - Sensor: m7004_ID_B700000D569E0C28\n",
      "2025-05-22 09:09:36,511 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:36,511 - INFO - Initial records: 100698\n",
      "2025-05-22 09:09:36,512 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:36,512 - INFO - Final records: 100698\n",
      "2025-05-22 09:09:36,606 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240108/data/m7004_ID_B700000D569E0C28.txt. Skipping file.\n",
      "2025-05-22 09:09:36,607 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240108/data/m7004_ID_37F6F9511A64FF28.txt\n",
      "2025-05-22 09:09:36,607 - INFO - Sensor: m7004_ID_37F6F9511A64FF28\n",
      "2025-05-22 09:09:36,676 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:36,677 - INFO - Initial records: 134188\n",
      "2025-05-22 09:09:36,677 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:36,678 - INFO - Final records: 134188\n",
      "2025-05-22 09:09:36,826 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240108/data/m7004_ID_37F6F9511A64FF28.txt. Skipping file.\n",
      "2025-05-22 09:09:36,827 - INFO - Processing file: /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240108/data/m7004_ID_DB00000B2A5F9F28.txt\n",
      "2025-05-22 09:09:36,827 - INFO - Sensor: m7004_ID_DB00000B2A5F9F28\n",
      "2025-05-22 09:09:36,896 - INFO - Validation statistics:\n",
      "2025-05-22 09:09:36,897 - INFO - Initial records: 134188\n",
      "2025-05-22 09:09:36,898 - INFO - Removed timestamp NaN values: 0\n",
      "2025-05-22 09:09:36,899 - INFO - Final records: 134188\n",
      "2025-05-22 09:09:37,017 - INFO - Data already exists for /home/jovyan/sample_data/datasets/PeroCube-sample-data/data_20240108/data/m7004_ID_DB00000B2A5F9F28.txt. Skipping file.\n",
      "2025-05-22 09:09:37,018 - INFO - Processing complete. Processed 0 files, skipped 43 files, errors in 0 files. Inserted 0 data points in 4.75 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting temperature data processing from directory: {ROOT_DIRECTORY}\")\n",
    "stats = process_temperature_files(ROOT_DIRECTORY, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03eb193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " File Processing\n",
      "\n",
      " Total files found:                   43\n",
      " Successfully processed:               0\n",
      "  Skipped (existing/empty):            43\n",
      " Errors during processing:             0\n",
      "\n",
      " Data Statistics\n",
      "\n",
      " Data points inserted:                 0\n",
      "\n",
      " Performance Metrics\n",
      "\n",
      "  Total processing time:            4.8s\n",
      "\n",
      "  Database Status\n",
      "\n",
      " Total records in database:   2,878,659\n"
     ]
    }
   ],
   "source": [
    "def format_duration(seconds):\n",
    "    \"\"\"Format duration in a human-readable format\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = seconds % 60\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h {minutes}m {secs:.1f}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}m {secs:.1f}s\"\n",
    "    else:\n",
    "        return f\"{secs:.1f}s\"\n",
    "\n",
    "def format_number(n):\n",
    "    \"\"\"Format number with thousand separators\"\"\"\n",
    "    return f\"{n:,}\"\n",
    "\n",
    "# Display processing statistics\n",
    "if 'stats' in locals():\n",
    "    print(\" File Processing\")\n",
    "    print(\"\")\n",
    "    print(f\" Total files found:           {format_number(stats.get('total_files', 0)):>10}\")\n",
    "    print(f\" Successfully processed:      {format_number(stats.get('files_processed', 0)):>10}\")\n",
    "    print(f\"  Skipped (existing/empty):    {format_number(stats.get('files_skipped', 0)):>10}\")\n",
    "    print(f\" Errors during processing:    {format_number(stats.get('files_error', 0)):>10}\")\n",
    "    \n",
    "    print(\"\\n Data Statistics\")\n",
    "    print(\"\")\n",
    "    print(f\" Data points inserted:        {format_number(stats.get('rows_inserted', 0)):>10}\")\n",
    "    \n",
    "    if 'duration_seconds' in stats:\n",
    "        duration = format_duration(stats['duration_seconds'])\n",
    "        print(\"\\n Performance Metrics\")\n",
    "        print(\"\")\n",
    "        print(f\"  Total processing time:      {duration:>10}\")\n",
    "        \n",
    "        if stats.get('rows_inserted', 0) > 0 and stats.get('duration_seconds', 0) > 0:\n",
    "            throughput = stats['rows_inserted'] / stats['duration_seconds']\n",
    "            print(f\" Processing speed:           {format_number(int(throughput)):>10} rows/sec\")\n",
    "\n",
    "    # Database verification\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(\"SELECT COUNT(*) FROM temperature_measurement\"))\n",
    "            total_count = result.scalar()\n",
    "            \n",
    "            print(\"\\n  Database Status\")\n",
    "            print(\"\")\n",
    "            print(f\" Total records in database:  {format_number(total_count):>10}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"\\n  Could not verify database status:\")\n",
    "        print(f\"   {str(e)}\")\n",
    "else:\n",
    "    print(\" No statistics available - processing may have failed\")\n",
    "    print(\"   Please check the logs above for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018b8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d89a74a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
